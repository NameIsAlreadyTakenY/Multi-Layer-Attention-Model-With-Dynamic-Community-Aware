05/21/2022 20:18:36 - INFO: dict_items([('base_model', 'DyMADC'), ('model', 'default'), ('test_subset', 0.25), ('min_time', 1), ('max_time', 17), ('dataset', 'fb-forum'), ('dataname', 'fb-forum_16_by_edgesNumber_0.25'), ('time_steps', 17), ('GPU_ID', 0), ('epochs', 30), ('batch_size', 256), ('featureless', 'True'), ('max_gradient_norm', 1.0), ('test_freq', 1), ('val_freq', 1), ('neg_sample_size', 10), ('walk_len', 40), ('neg_weight', 1.0), ('learning_rate', 0.001), ('spatial_drop', 0.1), ('temporal_drop', 0.5), ('weight_decay', 0.0005), ('use_residual', 'False'), ('structural_head_config', '16,8,8'), ('structural_layer_config', '128'), ('temporal_head_config', '16'), ('temporal_layer_config', '128'), ('position_ffn', 'True'), ('optimizer', 'adam'), ('seed', 7), ('save_dir', '/output'), ('log_dir', '/log'), ('csv_dir', '/csv'), ('model_dir', '/model'), ('window', -1)])
05/21/2022 20:19:06 - INFO: # train: 25290, # test: 8430
05/21/2022 20:19:29 - WARNING: From D:\Anaconda3\envs\tf_1\lib\site-packages\tensorflow\python\ops\sparse_grad.py:281: calling sparse_reduce_sum (from tensorflow.python.ops.sparse_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
05/21/2022 20:20:30 - INFO: Mini batch Iter: 0 train_loss= 24.76196 graph_loss= 24.68510 reg_loss= 0.07686
05/21/2022 20:20:32 - INFO: Mini batch Iter: 1 train_loss= 23.70678 graph_loss= 23.63035 reg_loss= 0.07643
05/21/2022 20:20:33 - INFO: Mini batch Iter: 2 train_loss= 23.10479 graph_loss= 23.02876 reg_loss= 0.07603
05/21/2022 20:20:34 - INFO: Mini batch Iter: 3 train_loss= 22.70797 graph_loss= 22.63232 reg_loss= 0.07565
05/21/2022 20:20:34 - INFO: Time for epoch : 40.685961961746216
05/21/2022 20:20:44 - INFO: Test results at epoch 0: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000022015824840>, {'operator_hadamard': [0.757167511668911, 0.757167511668911]}) best is : operator_hadamard 0.757167511668911
05/21/2022 20:20:45 - INFO: Mini batch Iter: 0 train_loss= 22.54036 graph_loss= 22.46507 reg_loss= 0.07528
05/21/2022 20:20:47 - INFO: Mini batch Iter: 1 train_loss= 22.41540 graph_loss= 22.34047 reg_loss= 0.07493
05/21/2022 20:20:49 - INFO: Mini batch Iter: 2 train_loss= 22.32551 graph_loss= 22.25093 reg_loss= 0.07458
05/21/2022 20:20:50 - INFO: Mini batch Iter: 3 train_loss= 22.25195 graph_loss= 22.17773 reg_loss= 0.07422
05/21/2022 20:20:50 - INFO: Time for epoch : 1.9176743030548096
05/21/2022 20:20:52 - INFO: Test results at epoch 1: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201085CF28>, {'operator_hadamard': [0.7779332061256683, 0.7779332061256683]}) best is : operator_hadamard 0.7779332061256683
05/21/2022 20:20:54 - INFO: Mini batch Iter: 0 train_loss= 22.18559 graph_loss= 22.11172 reg_loss= 0.07387
05/21/2022 20:20:55 - INFO: Mini batch Iter: 1 train_loss= 22.21650 graph_loss= 22.14298 reg_loss= 0.07352
05/21/2022 20:20:57 - INFO: Mini batch Iter: 2 train_loss= 22.19533 graph_loss= 22.12215 reg_loss= 0.07318
05/21/2022 20:20:58 - INFO: Mini batch Iter: 3 train_loss= 22.12887 graph_loss= 22.05603 reg_loss= 0.07284
05/21/2022 20:20:58 - INFO: Time for epoch : 1.9549272060394287
05/21/2022 20:21:00 - INFO: Test results at epoch 2: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201D753F28>, {'operator_hadamard': [0.7843000060508071, 0.7843000060508071]}) best is : operator_hadamard 0.7843000060508071
05/21/2022 20:21:02 - INFO: Mini batch Iter: 0 train_loss= 22.11594 graph_loss= 22.04342 reg_loss= 0.07252
05/21/2022 20:21:03 - INFO: Mini batch Iter: 1 train_loss= 22.05455 graph_loss= 21.98233 reg_loss= 0.07222
05/21/2022 20:21:05 - INFO: Mini batch Iter: 2 train_loss= 22.02756 graph_loss= 21.95561 reg_loss= 0.07195
05/21/2022 20:21:06 - INFO: Mini batch Iter: 3 train_loss= 22.05912 graph_loss= 21.98742 reg_loss= 0.07169
05/21/2022 20:21:06 - INFO: Time for epoch : 1.9339854717254639
05/21/2022 20:21:08 - INFO: Test results at epoch 3: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201D7537B8>, {'operator_hadamard': [0.7867846785121769, 0.7867846785121769]}) best is : operator_hadamard 0.7867846785121769
05/21/2022 20:21:10 - INFO: Mini batch Iter: 0 train_loss= 22.03063 graph_loss= 21.95917 reg_loss= 0.07146
05/21/2022 20:21:11 - INFO: Mini batch Iter: 1 train_loss= 21.81478 graph_loss= 21.74352 reg_loss= 0.07125
05/21/2022 20:21:13 - INFO: Mini batch Iter: 2 train_loss= 22.03760 graph_loss= 21.96652 reg_loss= 0.07108
05/21/2022 20:21:14 - INFO: Mini batch Iter: 3 train_loss= 21.82294 graph_loss= 21.75201 reg_loss= 0.07093
05/21/2022 20:21:14 - INFO: Time for epoch : 1.9307775497436523
05/21/2022 20:21:16 - INFO: Test results at epoch 4: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000022015824E18>, {'operator_hadamard': [0.7918863391069291, 0.7918863391069291]}) best is : operator_hadamard 0.7918863391069291
05/21/2022 20:21:18 - INFO: Mini batch Iter: 0 train_loss= 21.81915 graph_loss= 21.74833 reg_loss= 0.07081
05/21/2022 20:21:20 - INFO: Mini batch Iter: 1 train_loss= 21.54362 graph_loss= 21.47289 reg_loss= 0.07072
05/21/2022 20:21:21 - INFO: Mini batch Iter: 2 train_loss= 21.58315 graph_loss= 21.51249 reg_loss= 0.07066
05/21/2022 20:21:22 - INFO: Mini batch Iter: 3 train_loss= 21.40066 graph_loss= 21.33003 reg_loss= 0.07063
05/21/2022 20:21:22 - INFO: Time for epoch : 1.8865444660186768
05/21/2022 20:21:25 - INFO: Test results at epoch 5: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C091E0>, {'operator_hadamard': [0.7951051714700225, 0.7951051714700225]}) best is : operator_hadamard 0.7951051714700225
05/21/2022 20:21:26 - INFO: Mini batch Iter: 0 train_loss= 21.24395 graph_loss= 21.17332 reg_loss= 0.07063
05/21/2022 20:21:28 - INFO: Mini batch Iter: 1 train_loss= 21.44054 graph_loss= 21.36988 reg_loss= 0.07066
05/21/2022 20:21:30 - INFO: Mini batch Iter: 2 train_loss= 21.11712 graph_loss= 21.04641 reg_loss= 0.07071
05/21/2022 20:21:31 - INFO: Mini batch Iter: 3 train_loss= 21.21897 graph_loss= 21.14820 reg_loss= 0.07077
05/21/2022 20:21:31 - INFO: Time for epoch : 2.033010721206665
05/21/2022 20:21:33 - INFO: Test results at epoch 6: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C099D8>, {'operator_hadamard': [0.7981805785978732, 0.7981805785978732]}) best is : operator_hadamard 0.7981805785978732
05/21/2022 20:21:35 - INFO: Mini batch Iter: 0 train_loss= 21.17920 graph_loss= 21.10835 reg_loss= 0.07085
05/21/2022 20:21:37 - INFO: Mini batch Iter: 1 train_loss= 20.94115 graph_loss= 20.87021 reg_loss= 0.07094
05/21/2022 20:21:38 - INFO: Mini batch Iter: 2 train_loss= 20.59753 graph_loss= 20.52649 reg_loss= 0.07104
05/21/2022 20:21:39 - INFO: Mini batch Iter: 3 train_loss= 20.24184 graph_loss= 20.17070 reg_loss= 0.07115
05/21/2022 20:21:39 - INFO: Time for epoch : 1.9925768375396729
05/21/2022 20:21:42 - INFO: Test results at epoch 7: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09620>, {'operator_hadamard': [0.801704885252776, 0.801704885252776]}) best is : operator_hadamard 0.801704885252776
05/21/2022 20:21:43 - INFO: Mini batch Iter: 0 train_loss= 20.87387 graph_loss= 20.80261 reg_loss= 0.07125
05/21/2022 20:21:45 - INFO: Mini batch Iter: 1 train_loss= 20.72860 graph_loss= 20.65725 reg_loss= 0.07135
05/21/2022 20:21:47 - INFO: Mini batch Iter: 2 train_loss= 20.77649 graph_loss= 20.70503 reg_loss= 0.07146
05/21/2022 20:21:48 - INFO: Mini batch Iter: 3 train_loss= 19.93877 graph_loss= 19.86721 reg_loss= 0.07156
05/21/2022 20:21:48 - INFO: Time for epoch : 2.0264503955841064
05/21/2022 20:21:50 - INFO: Test results at epoch 8: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201085CEA0>, {'operator_hadamard': [0.8049023990746487, 0.8049023990746487]}) best is : operator_hadamard 0.8049023990746487
05/21/2022 20:21:52 - INFO: Mini batch Iter: 0 train_loss= 20.84011 graph_loss= 20.76845 reg_loss= 0.07166
05/21/2022 20:21:54 - INFO: Mini batch Iter: 1 train_loss= 20.55792 graph_loss= 20.48618 reg_loss= 0.07174
05/21/2022 20:21:55 - INFO: Mini batch Iter: 2 train_loss= 20.61893 graph_loss= 20.54712 reg_loss= 0.07181
05/21/2022 20:21:56 - INFO: Mini batch Iter: 3 train_loss= 21.10476 graph_loss= 21.03290 reg_loss= 0.07186
05/21/2022 20:21:56 - INFO: Time for epoch : 2.004141092300415
05/21/2022 20:21:59 - INFO: Test results at epoch 9: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09EA0>, {'operator_hadamard': [0.8076205201161192, 0.8076205201161192]}) best is : operator_hadamard 0.8076205201161192
05/21/2022 20:22:00 - INFO: Mini batch Iter: 0 train_loss= 20.78341 graph_loss= 20.71150 reg_loss= 0.07190
05/21/2022 20:22:02 - INFO: Mini batch Iter: 1 train_loss= 20.56139 graph_loss= 20.48946 reg_loss= 0.07193
05/21/2022 20:22:04 - INFO: Mini batch Iter: 2 train_loss= 20.10493 graph_loss= 20.03299 reg_loss= 0.07194
05/21/2022 20:22:05 - INFO: Mini batch Iter: 3 train_loss= 20.62124 graph_loss= 20.54930 reg_loss= 0.07194
05/21/2022 20:22:05 - INFO: Time for epoch : 1.8765337467193604
05/21/2022 20:22:07 - INFO: Test results at epoch 10: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201085C598>, {'operator_hadamard': [0.8082709255905517, 0.8082709255905517]}) best is : operator_hadamard 0.8082709255905517
05/21/2022 20:22:09 - INFO: Mini batch Iter: 0 train_loss= 20.50820 graph_loss= 20.43626 reg_loss= 0.07193
05/21/2022 20:22:10 - INFO: Mini batch Iter: 1 train_loss= 20.41423 graph_loss= 20.34231 reg_loss= 0.07192
05/21/2022 20:22:12 - INFO: Mini batch Iter: 2 train_loss= 20.94122 graph_loss= 20.86930 reg_loss= 0.07191
05/21/2022 20:22:13 - INFO: Mini batch Iter: 3 train_loss= 20.75519 graph_loss= 20.68330 reg_loss= 0.07190
05/21/2022 20:22:13 - INFO: Time for epoch : 1.8760831356048584
05/21/2022 20:22:16 - INFO: Test results at epoch 11: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09EA0>, {'operator_hadamard': [0.8096004426939317, 0.8096004426939317]}) best is : operator_hadamard 0.8096004426939317
05/21/2022 20:22:17 - INFO: Mini batch Iter: 0 train_loss= 19.87708 graph_loss= 19.80519 reg_loss= 0.07189
05/21/2022 20:22:19 - INFO: Mini batch Iter: 1 train_loss= 20.87357 graph_loss= 20.80169 reg_loss= 0.07188
05/21/2022 20:22:21 - INFO: Mini batch Iter: 2 train_loss= 19.61740 graph_loss= 19.54553 reg_loss= 0.07186
05/21/2022 20:22:22 - INFO: Mini batch Iter: 3 train_loss= 21.50265 graph_loss= 21.43080 reg_loss= 0.07185
05/21/2022 20:22:22 - INFO: Time for epoch : 1.8920955657958984
05/21/2022 20:22:24 - INFO: Test results at epoch 12: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201D753D90>, {'operator_hadamard': [0.8101416381364077, 0.8101416381364077]}) best is : operator_hadamard 0.8101416381364077
05/21/2022 20:22:26 - INFO: Mini batch Iter: 0 train_loss= 20.63843 graph_loss= 20.56660 reg_loss= 0.07183
05/21/2022 20:22:28 - INFO: Mini batch Iter: 1 train_loss= 20.15935 graph_loss= 20.08755 reg_loss= 0.07181
05/21/2022 20:22:29 - INFO: Mini batch Iter: 2 train_loss= 19.71502 graph_loss= 19.64323 reg_loss= 0.07179
05/21/2022 20:22:30 - INFO: Mini batch Iter: 3 train_loss= 20.51447 graph_loss= 20.44270 reg_loss= 0.07177
05/21/2022 20:22:30 - INFO: Time for epoch : 1.9296705722808838
05/21/2022 20:22:32 - INFO: Test results at epoch 13: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201D753EA0>, {'operator_hadamard': [0.8078535606185332, 0.8078535606185332]}) best is : operator_hadamard 0.8078535606185332
05/21/2022 20:22:34 - INFO: Mini batch Iter: 0 train_loss= 20.79071 graph_loss= 20.71897 reg_loss= 0.07175
05/21/2022 20:22:36 - INFO: Mini batch Iter: 1 train_loss= 20.80149 graph_loss= 20.72977 reg_loss= 0.07172
05/21/2022 20:22:37 - INFO: Mini batch Iter: 2 train_loss= 20.45151 graph_loss= 20.37981 reg_loss= 0.07171
05/21/2022 20:22:38 - INFO: Mini batch Iter: 3 train_loss= 20.15058 graph_loss= 20.07888 reg_loss= 0.07170
05/21/2022 20:22:38 - INFO: Time for epoch : 1.9325687885284424
05/21/2022 20:22:41 - INFO: Test results at epoch 14: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201085C7B8>, {'operator_hadamard': [0.8056762973000737, 0.8056762973000737]}) best is : operator_hadamard 0.8056762973000737
05/21/2022 20:22:42 - INFO: Mini batch Iter: 0 train_loss= 19.87553 graph_loss= 19.80383 reg_loss= 0.07170
05/21/2022 20:22:44 - INFO: Mini batch Iter: 1 train_loss= 20.39675 graph_loss= 20.32504 reg_loss= 0.07171
05/21/2022 20:22:46 - INFO: Mini batch Iter: 2 train_loss= 20.06991 graph_loss= 19.99818 reg_loss= 0.07173
05/21/2022 20:22:47 - INFO: Mini batch Iter: 3 train_loss= 20.50957 graph_loss= 20.43783 reg_loss= 0.07174
05/21/2022 20:22:47 - INFO: Time for epoch : 2.015568256378174
05/21/2022 20:22:49 - INFO: Test results at epoch 15: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000220158247B8>, {'operator_hadamard': [0.8043901138255313, 0.8043901138255313]}) best is : operator_hadamard 0.8043901138255313
05/21/2022 20:22:51 - INFO: Mini batch Iter: 0 train_loss= 20.24493 graph_loss= 20.17319 reg_loss= 0.07174
05/21/2022 20:22:52 - INFO: Mini batch Iter: 1 train_loss= 20.91491 graph_loss= 20.84316 reg_loss= 0.07175
05/21/2022 20:22:54 - INFO: Mini batch Iter: 2 train_loss= 20.38083 graph_loss= 20.30908 reg_loss= 0.07175
05/21/2022 20:22:55 - INFO: Mini batch Iter: 3 train_loss= 19.35377 graph_loss= 19.28202 reg_loss= 0.07175
05/21/2022 20:22:55 - INFO: Time for epoch : 1.9739720821380615
05/21/2022 20:22:58 - INFO: Test results at epoch 16: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09378>, {'operator_hadamard': [0.8042806645756203, 0.8042806645756203]}) best is : operator_hadamard 0.8042806645756203
05/21/2022 20:23:00 - INFO: Mini batch Iter: 0 train_loss= 20.46057 graph_loss= 20.38881 reg_loss= 0.07176
05/21/2022 20:23:01 - INFO: Mini batch Iter: 1 train_loss= 20.37742 graph_loss= 20.30566 reg_loss= 0.07176
05/21/2022 20:23:03 - INFO: Mini batch Iter: 2 train_loss= 20.00691 graph_loss= 19.93515 reg_loss= 0.07176
05/21/2022 20:23:04 - INFO: Mini batch Iter: 3 train_loss= 20.33644 graph_loss= 20.26466 reg_loss= 0.07178
05/21/2022 20:23:04 - INFO: Time for epoch : 1.9496161937713623
05/21/2022 20:23:06 - INFO: Test results at epoch 17: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C099D8>, {'operator_hadamard': [0.8055169007484708, 0.8055169007484708]}) best is : operator_hadamard 0.8055169007484708
05/21/2022 20:23:08 - INFO: Mini batch Iter: 0 train_loss= 20.56618 graph_loss= 20.49440 reg_loss= 0.07178
05/21/2022 20:23:10 - INFO: Mini batch Iter: 1 train_loss= 20.07351 graph_loss= 20.00173 reg_loss= 0.07178
05/21/2022 20:23:12 - INFO: Mini batch Iter: 2 train_loss= 20.15805 graph_loss= 20.08627 reg_loss= 0.07178
05/21/2022 20:23:13 - INFO: Mini batch Iter: 3 train_loss= 20.14289 graph_loss= 20.07110 reg_loss= 0.07179
05/21/2022 20:23:13 - INFO: Time for epoch : 2.0118250846862793
05/21/2022 20:23:15 - INFO: Test results at epoch 18: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C14E18>, {'operator_hadamard': [0.8067015362014158, 0.8067015362014158]}) best is : operator_hadamard 0.8067015362014158
05/21/2022 20:23:17 - INFO: Mini batch Iter: 0 train_loss= 19.67628 graph_loss= 19.60448 reg_loss= 0.07180
05/21/2022 20:23:18 - INFO: Mini batch Iter: 1 train_loss= 19.81731 graph_loss= 19.74549 reg_loss= 0.07182
05/21/2022 20:23:20 - INFO: Mini batch Iter: 2 train_loss= 20.23980 graph_loss= 20.16797 reg_loss= 0.07183
05/21/2022 20:23:21 - INFO: Mini batch Iter: 3 train_loss= 19.63141 graph_loss= 19.55957 reg_loss= 0.07184
05/21/2022 20:23:21 - INFO: Time for epoch : 1.9258692264556885
05/21/2022 20:23:23 - INFO: Test results at epoch 19: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C098C8>, {'operator_hadamard': [0.807216509134608, 0.807216509134608]}) best is : operator_hadamard 0.807216509134608
05/21/2022 20:23:25 - INFO: Mini batch Iter: 0 train_loss= 20.13144 graph_loss= 20.05959 reg_loss= 0.07186
05/21/2022 20:23:27 - INFO: Mini batch Iter: 1 train_loss= 19.96656 graph_loss= 19.89468 reg_loss= 0.07188
05/21/2022 20:23:28 - INFO: Mini batch Iter: 2 train_loss= 19.39380 graph_loss= 19.32190 reg_loss= 0.07190
05/21/2022 20:23:30 - INFO: Mini batch Iter: 3 train_loss= 20.40023 graph_loss= 20.32830 reg_loss= 0.07193
05/21/2022 20:23:30 - INFO: Time for epoch : 1.928096055984497
05/21/2022 20:23:32 - INFO: Test results at epoch 20: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201085C950>, {'operator_hadamard': [0.8083487699272074, 0.8083487699272074]}) best is : operator_hadamard 0.8083487699272074
05/21/2022 20:23:34 - INFO: Mini batch Iter: 0 train_loss= 20.53436 graph_loss= 20.46240 reg_loss= 0.07196
05/21/2022 20:23:35 - INFO: Mini batch Iter: 1 train_loss= 19.99710 graph_loss= 19.92510 reg_loss= 0.07200
05/21/2022 20:23:37 - INFO: Mini batch Iter: 2 train_loss= 19.62166 graph_loss= 19.54963 reg_loss= 0.07203
05/21/2022 20:23:38 - INFO: Mini batch Iter: 3 train_loss= 21.04488 graph_loss= 20.97282 reg_loss= 0.07206
05/21/2022 20:23:38 - INFO: Time for epoch : 1.8940749168395996
05/21/2022 20:23:40 - INFO: Test results at epoch 21: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C141E0>, {'operator_hadamard': [0.810190382312506, 0.810190382312506]}) best is : operator_hadamard 0.810190382312506
05/21/2022 20:23:42 - INFO: Mini batch Iter: 0 train_loss= 19.78868 graph_loss= 19.71661 reg_loss= 0.07207
05/21/2022 20:23:44 - INFO: Mini batch Iter: 1 train_loss= 20.47042 graph_loss= 20.39835 reg_loss= 0.07207
05/21/2022 20:23:45 - INFO: Mini batch Iter: 2 train_loss= 20.43629 graph_loss= 20.36423 reg_loss= 0.07207
05/21/2022 20:23:46 - INFO: Mini batch Iter: 3 train_loss= 19.10530 graph_loss= 19.03324 reg_loss= 0.07206
05/21/2022 20:23:46 - INFO: Time for epoch : 2.0089168548583984
05/21/2022 20:23:49 - INFO: Test results at epoch 22: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09400>, {'operator_hadamard': [0.80813065943947, 0.80813065943947]}) best is : operator_hadamard 0.80813065943947
05/21/2022 20:23:50 - INFO: Mini batch Iter: 0 train_loss= 20.37551 graph_loss= 20.30346 reg_loss= 0.07205
05/21/2022 20:23:52 - INFO: Mini batch Iter: 1 train_loss= 20.16026 graph_loss= 20.08822 reg_loss= 0.07205
05/21/2022 20:23:54 - INFO: Mini batch Iter: 2 train_loss= 19.48796 graph_loss= 19.41592 reg_loss= 0.07204
05/21/2022 20:23:55 - INFO: Mini batch Iter: 3 train_loss= 20.29527 graph_loss= 20.22324 reg_loss= 0.07203
05/21/2022 20:23:55 - INFO: Time for epoch : 2.0185115337371826
05/21/2022 20:23:57 - INFO: Test results at epoch 23: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002201D753510>, {'operator_hadamard': [0.8066408100201365, 0.8066408100201365]}) best is : operator_hadamard 0.8066408100201365
05/21/2022 20:23:59 - INFO: Mini batch Iter: 0 train_loss= 20.45066 graph_loss= 20.37862 reg_loss= 0.07204
05/21/2022 20:24:00 - INFO: Mini batch Iter: 1 train_loss= 20.00354 graph_loss= 19.93149 reg_loss= 0.07205
05/21/2022 20:24:02 - INFO: Mini batch Iter: 2 train_loss= 20.26056 graph_loss= 20.18848 reg_loss= 0.07207
05/21/2022 20:24:03 - INFO: Mini batch Iter: 3 train_loss= 19.73312 graph_loss= 19.66104 reg_loss= 0.07209
05/21/2022 20:24:03 - INFO: Time for epoch : 1.8994181156158447
05/21/2022 20:24:05 - INFO: Test results at epoch 24: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C14BF8>, {'operator_hadamard': [0.808896874547069, 0.808896874547069]}) best is : operator_hadamard 0.808896874547069
05/21/2022 20:24:07 - INFO: Mini batch Iter: 0 train_loss= 19.38751 graph_loss= 19.31540 reg_loss= 0.07211
05/21/2022 20:24:09 - INFO: Mini batch Iter: 1 train_loss= 20.08489 graph_loss= 20.01277 reg_loss= 0.07213
05/21/2022 20:24:11 - INFO: Mini batch Iter: 2 train_loss= 20.60247 graph_loss= 20.53033 reg_loss= 0.07214
05/21/2022 20:24:12 - INFO: Mini batch Iter: 3 train_loss= 20.06445 graph_loss= 19.99230 reg_loss= 0.07215
05/21/2022 20:24:12 - INFO: Time for epoch : 1.9777421951293945
05/21/2022 20:24:14 - INFO: Test results at epoch 25: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000022015824598>, {'operator_hadamard': [0.8085216822932277, 0.8085216822932277]}) best is : operator_hadamard 0.8085216822932277
05/21/2022 20:24:16 - INFO: Mini batch Iter: 0 train_loss= 19.60034 graph_loss= 19.52818 reg_loss= 0.07216
05/21/2022 20:24:17 - INFO: Mini batch Iter: 1 train_loss= 20.49528 graph_loss= 20.42311 reg_loss= 0.07217
05/21/2022 20:24:19 - INFO: Mini batch Iter: 2 train_loss= 19.46470 graph_loss= 19.39252 reg_loss= 0.07219
05/21/2022 20:24:20 - INFO: Mini batch Iter: 3 train_loss= 20.25863 graph_loss= 20.18642 reg_loss= 0.07220
05/21/2022 20:24:20 - INFO: Time for epoch : 2.03611421585083
05/21/2022 20:24:22 - INFO: Test results at epoch 26: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C141E0>, {'operator_hadamard': [0.8074327480936438, 0.8074327480936438]}) best is : operator_hadamard 0.8074327480936438
05/21/2022 20:24:24 - INFO: Mini batch Iter: 0 train_loss= 19.78902 graph_loss= 19.71680 reg_loss= 0.07222
05/21/2022 20:24:26 - INFO: Mini batch Iter: 1 train_loss= 20.07754 graph_loss= 20.00530 reg_loss= 0.07224
05/21/2022 20:24:28 - INFO: Mini batch Iter: 2 train_loss= 20.52986 graph_loss= 20.45761 reg_loss= 0.07225
05/21/2022 20:24:29 - INFO: Mini batch Iter: 3 train_loss= 19.41464 graph_loss= 19.34238 reg_loss= 0.07226
05/21/2022 20:24:29 - INFO: Time for epoch : 1.9712646007537842
05/21/2022 20:24:31 - INFO: Test results at epoch 27: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09510>, {'operator_hadamard': [0.8074204635481088, 0.8074204635481088]}) best is : operator_hadamard 0.8074204635481088
05/21/2022 20:24:33 - INFO: Mini batch Iter: 0 train_loss= 20.12198 graph_loss= 20.04970 reg_loss= 0.07228
05/21/2022 20:24:34 - INFO: Mini batch Iter: 1 train_loss= 20.64360 graph_loss= 20.57130 reg_loss= 0.07230
05/21/2022 20:24:36 - INFO: Mini batch Iter: 2 train_loss= 20.21216 graph_loss= 20.13985 reg_loss= 0.07231
05/21/2022 20:24:37 - INFO: Mini batch Iter: 3 train_loss= 20.28359 graph_loss= 20.21128 reg_loss= 0.07231
05/21/2022 20:24:37 - INFO: Time for epoch : 2.0793631076812744
05/21/2022 20:24:39 - INFO: Test results at epoch 28: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C096A8>, {'operator_hadamard': [0.8088089689846887, 0.8088089689846887]}) best is : operator_hadamard 0.8088089689846887
05/21/2022 20:24:41 - INFO: Mini batch Iter: 0 train_loss= 19.90140 graph_loss= 19.82909 reg_loss= 0.07231
05/21/2022 20:24:43 - INFO: Mini batch Iter: 1 train_loss= 20.28965 graph_loss= 20.21735 reg_loss= 0.07230
05/21/2022 20:24:45 - INFO: Mini batch Iter: 2 train_loss= 19.63664 graph_loss= 19.56435 reg_loss= 0.07229
05/21/2022 20:24:46 - INFO: Mini batch Iter: 3 train_loss= 19.89298 graph_loss= 19.82069 reg_loss= 0.07229
05/21/2022 20:24:46 - INFO: Time for epoch : 2.002599000930786
05/21/2022 20:24:48 - INFO: Test results at epoch 29: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C09840>, {'operator_hadamard': [0.8075171638882204, 0.8075171638882204]}) best is : operator_hadamard 0.8075171638882204
05/21/2022 20:24:48 - INFO: Best epoch 21
05/21/2022 20:24:50 - INFO: Best epoch test results defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x0000021FA0C096A8>, {'operator_hadamard': [0.810190382312506, 0.810190382312506]})

