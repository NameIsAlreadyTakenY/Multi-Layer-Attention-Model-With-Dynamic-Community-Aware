05/21/2022 15:06:04 - INFO: dict_items([('base_model', 'DyMADC'), ('model', 'default'), ('test_subset', 0.25), ('min_time', 1), ('max_time', 9), ('dataset', 'reddit'), ('dataname', 'reddit_8_by_edgesNumber_0.25'), ('time_steps', 9), ('GPU_ID', 0), ('epochs', 30), ('batch_size', 256), ('featureless', 'True'), ('max_gradient_norm', 1.0), ('test_freq', 1), ('val_freq', 1), ('neg_sample_size', 10), ('walk_len', 40), ('neg_weight', 1.0), ('learning_rate', 0.001), ('spatial_drop', 0.1), ('temporal_drop', 0.5), ('weight_decay', 0.0005), ('use_residual', 'False'), ('structural_head_config', '16,8,8'), ('structural_layer_config', '128'), ('temporal_head_config', '16'), ('temporal_layer_config', '16'), ('position_ffn', 'True'), ('optimizer', 'adam'), ('seed', 7), ('save_dir', '/output'), ('log_dir', '/log'), ('csv_dir', '/csv'), ('model_dir', '/model'), ('window', -1)])
05/21/2022 15:07:39 - INFO: # train: 504335, # test: 168112
05/21/2022 15:08:08 - WARNING: From D:\Anaconda3\envs\tf_1\lib\site-packages\tensorflow\python\ops\sparse_grad.py:281: calling sparse_reduce_sum (from tensorflow.python.ops.sparse_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
05/21/2022 15:08:42 - INFO: Mini batch Iter: 0 train_loss= 13.16906 graph_loss= 13.09117 reg_loss= 0.07789
05/21/2022 15:08:46 - INFO: Mini batch Iter: 1 train_loss= 12.24930 graph_loss= 12.17146 reg_loss= 0.07783
05/21/2022 15:08:49 - INFO: Mini batch Iter: 2 train_loss= 12.18189 graph_loss= 12.10394 reg_loss= 0.07795
05/21/2022 15:08:51 - INFO: Mini batch Iter: 3 train_loss= 11.72963 graph_loss= 11.65148 reg_loss= 0.07815
05/21/2022 15:08:54 - INFO: Mini batch Iter: 4 train_loss= 11.72351 graph_loss= 11.64510 reg_loss= 0.07841
05/21/2022 15:08:58 - INFO: Mini batch Iter: 5 train_loss= 11.43532 graph_loss= 11.35667 reg_loss= 0.07865
05/21/2022 15:09:01 - INFO: Mini batch Iter: 6 train_loss= 11.11039 graph_loss= 11.03161 reg_loss= 0.07878
05/21/2022 15:09:04 - INFO: Mini batch Iter: 7 train_loss= 10.92222 graph_loss= 10.84331 reg_loss= 0.07892
05/21/2022 15:09:06 - INFO: Mini batch Iter: 8 train_loss= 10.98102 graph_loss= 10.90193 reg_loss= 0.07909
05/21/2022 15:09:09 - INFO: Mini batch Iter: 9 train_loss= 10.69447 graph_loss= 10.61523 reg_loss= 0.07924
05/21/2022 15:09:12 - INFO: Mini batch Iter: 10 train_loss= 11.26229 graph_loss= 11.18283 reg_loss= 0.07945
05/21/2022 15:09:14 - INFO: Mini batch Iter: 11 train_loss= 10.84256 graph_loss= 10.76286 reg_loss= 0.07970
05/21/2022 15:09:18 - INFO: Mini batch Iter: 12 train_loss= 10.94269 graph_loss= 10.86273 reg_loss= 0.07996
05/21/2022 15:09:20 - INFO: Mini batch Iter: 13 train_loss= 11.35167 graph_loss= 11.27152 reg_loss= 0.08015
05/21/2022 15:09:23 - INFO: Mini batch Iter: 14 train_loss= 10.69732 graph_loss= 10.61696 reg_loss= 0.08036
05/21/2022 15:09:25 - INFO: Mini batch Iter: 15 train_loss= 10.94275 graph_loss= 10.86218 reg_loss= 0.08057
05/21/2022 15:09:28 - INFO: Mini batch Iter: 16 train_loss= 10.68553 graph_loss= 10.60476 reg_loss= 0.08077
05/21/2022 15:09:31 - INFO: Mini batch Iter: 17 train_loss= 11.03922 graph_loss= 10.95826 reg_loss= 0.08096
05/21/2022 15:09:34 - INFO: Mini batch Iter: 18 train_loss= 10.76047 graph_loss= 10.67936 reg_loss= 0.08111
05/21/2022 15:09:37 - INFO: Mini batch Iter: 19 train_loss= 10.78054 graph_loss= 10.69929 reg_loss= 0.08125
05/21/2022 15:09:40 - INFO: Mini batch Iter: 20 train_loss= 10.62985 graph_loss= 10.54845 reg_loss= 0.08140
05/21/2022 15:09:42 - INFO: Mini batch Iter: 21 train_loss= 10.94643 graph_loss= 10.86488 reg_loss= 0.08154
05/21/2022 15:09:45 - INFO: Mini batch Iter: 22 train_loss= 10.87659 graph_loss= 10.79492 reg_loss= 0.08167
05/21/2022 15:09:48 - INFO: Mini batch Iter: 23 train_loss= 11.02187 graph_loss= 10.94008 reg_loss= 0.08179
05/21/2022 15:09:50 - INFO: Mini batch Iter: 24 train_loss= 10.67236 graph_loss= 10.59047 reg_loss= 0.08188
05/21/2022 15:09:53 - INFO: Mini batch Iter: 25 train_loss= 10.96332 graph_loss= 10.88132 reg_loss= 0.08200
05/21/2022 15:09:55 - INFO: Mini batch Iter: 26 train_loss= 10.88242 graph_loss= 10.80029 reg_loss= 0.08213
05/21/2022 15:09:58 - INFO: Mini batch Iter: 27 train_loss= 10.68707 graph_loss= 10.60482 reg_loss= 0.08225
05/21/2022 15:10:00 - INFO: Mini batch Iter: 28 train_loss= 10.63978 graph_loss= 10.55741 reg_loss= 0.08237
05/21/2022 15:10:03 - INFO: Mini batch Iter: 29 train_loss= 10.80122 graph_loss= 10.71872 reg_loss= 0.08250
05/21/2022 15:10:05 - INFO: Mini batch Iter: 30 train_loss= 10.67143 graph_loss= 10.58882 reg_loss= 0.08261
05/21/2022 15:10:08 - INFO: Mini batch Iter: 31 train_loss= 11.13340 graph_loss= 11.05070 reg_loss= 0.08270
05/21/2022 15:10:10 - INFO: Mini batch Iter: 32 train_loss= 10.51174 graph_loss= 10.42896 reg_loss= 0.08278
05/21/2022 15:10:14 - INFO: Mini batch Iter: 33 train_loss= 11.26463 graph_loss= 11.18177 reg_loss= 0.08287
05/21/2022 15:10:16 - INFO: Mini batch Iter: 34 train_loss= 10.89867 graph_loss= 10.81573 reg_loss= 0.08294
05/21/2022 15:10:19 - INFO: Mini batch Iter: 35 train_loss= 10.78916 graph_loss= 10.70616 reg_loss= 0.08300
05/21/2022 15:10:21 - INFO: Mini batch Iter: 36 train_loss= 10.72439 graph_loss= 10.64134 reg_loss= 0.08306
05/21/2022 15:10:24 - INFO: Mini batch Iter: 37 train_loss= 10.88693 graph_loss= 10.80382 reg_loss= 0.08310
05/21/2022 15:10:27 - INFO: Mini batch Iter: 38 train_loss= 10.64329 graph_loss= 10.56015 reg_loss= 0.08314
05/21/2022 15:10:28 - INFO: Mini batch Iter: 39 train_loss= 11.04375 graph_loss= 10.96058 reg_loss= 0.08318
05/21/2022 15:10:28 - INFO: Time for epoch : 94.00179553031921
05/21/2022 15:15:22 - INFO: Test results at epoch 0: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E3048>, {'operator_hadamard': [0.9627234860533386, 0.9627234860533386]}) best is : operator_hadamard 0.9627234860533386
05/21/2022 15:15:25 - INFO: Mini batch Iter: 0 train_loss= 10.51551 graph_loss= 10.43230 reg_loss= 0.08321
05/21/2022 15:15:27 - INFO: Mini batch Iter: 1 train_loss= 10.56173 graph_loss= 10.47848 reg_loss= 0.08325
05/21/2022 15:15:30 - INFO: Mini batch Iter: 2 train_loss= 10.79572 graph_loss= 10.71240 reg_loss= 0.08332
05/21/2022 15:15:33 - INFO: Mini batch Iter: 3 train_loss= 10.44834 graph_loss= 10.36497 reg_loss= 0.08337
05/21/2022 15:15:36 - INFO: Mini batch Iter: 4 train_loss= 10.61852 graph_loss= 10.53507 reg_loss= 0.08345
05/21/2022 15:15:38 - INFO: Mini batch Iter: 5 train_loss= 10.79681 graph_loss= 10.71329 reg_loss= 0.08352
05/21/2022 15:15:41 - INFO: Mini batch Iter: 6 train_loss= 11.08065 graph_loss= 10.99708 reg_loss= 0.08357
05/21/2022 15:15:43 - INFO: Mini batch Iter: 7 train_loss= 10.83704 graph_loss= 10.75344 reg_loss= 0.08360
05/21/2022 15:15:47 - INFO: Mini batch Iter: 8 train_loss= 10.50303 graph_loss= 10.41943 reg_loss= 0.08360
05/21/2022 15:15:50 - INFO: Mini batch Iter: 9 train_loss= 10.32619 graph_loss= 10.24257 reg_loss= 0.08362
05/21/2022 15:15:52 - INFO: Mini batch Iter: 10 train_loss= 11.66153 graph_loss= 11.57788 reg_loss= 0.08366
05/21/2022 15:15:55 - INFO: Mini batch Iter: 11 train_loss= 11.09353 graph_loss= 11.00983 reg_loss= 0.08370
05/21/2022 15:15:57 - INFO: Mini batch Iter: 12 train_loss= 11.23074 graph_loss= 11.14701 reg_loss= 0.08373
05/21/2022 15:16:01 - INFO: Mini batch Iter: 13 train_loss= 10.57452 graph_loss= 10.49077 reg_loss= 0.08375
05/21/2022 15:16:03 - INFO: Mini batch Iter: 14 train_loss= 10.66921 graph_loss= 10.58545 reg_loss= 0.08376
05/21/2022 15:16:06 - INFO: Mini batch Iter: 15 train_loss= 10.86312 graph_loss= 10.77939 reg_loss= 0.08374
05/21/2022 15:16:09 - INFO: Mini batch Iter: 16 train_loss= 10.63151 graph_loss= 10.54780 reg_loss= 0.08371
05/21/2022 15:16:12 - INFO: Mini batch Iter: 17 train_loss= 10.85443 graph_loss= 10.77075 reg_loss= 0.08368
05/21/2022 15:16:15 - INFO: Mini batch Iter: 18 train_loss= 11.68029 graph_loss= 11.59662 reg_loss= 0.08367
05/21/2022 15:16:18 - INFO: Mini batch Iter: 19 train_loss= 10.53453 graph_loss= 10.45090 reg_loss= 0.08363
05/21/2022 15:16:20 - INFO: Mini batch Iter: 20 train_loss= 10.74496 graph_loss= 10.66134 reg_loss= 0.08361
05/21/2022 15:16:23 - INFO: Mini batch Iter: 21 train_loss= 10.46952 graph_loss= 10.38591 reg_loss= 0.08361
05/21/2022 15:16:25 - INFO: Mini batch Iter: 22 train_loss= 10.62861 graph_loss= 10.54496 reg_loss= 0.08365
05/21/2022 15:16:28 - INFO: Mini batch Iter: 23 train_loss= 10.74892 graph_loss= 10.66521 reg_loss= 0.08371
05/21/2022 15:16:31 - INFO: Mini batch Iter: 24 train_loss= 10.61251 graph_loss= 10.52877 reg_loss= 0.08375
05/21/2022 15:16:34 - INFO: Mini batch Iter: 25 train_loss= 10.44086 graph_loss= 10.35707 reg_loss= 0.08379
05/21/2022 15:16:36 - INFO: Mini batch Iter: 26 train_loss= 10.39607 graph_loss= 10.31224 reg_loss= 0.08383
05/21/2022 15:16:39 - INFO: Mini batch Iter: 27 train_loss= 10.75215 graph_loss= 10.66824 reg_loss= 0.08390
05/21/2022 15:16:42 - INFO: Mini batch Iter: 28 train_loss= 10.89209 graph_loss= 10.80811 reg_loss= 0.08398
05/21/2022 15:16:44 - INFO: Mini batch Iter: 29 train_loss= 10.77253 graph_loss= 10.68850 reg_loss= 0.08403
05/21/2022 15:16:47 - INFO: Mini batch Iter: 30 train_loss= 10.97762 graph_loss= 10.89354 reg_loss= 0.08408
05/21/2022 15:16:50 - INFO: Mini batch Iter: 31 train_loss= 10.47674 graph_loss= 10.39262 reg_loss= 0.08412
05/21/2022 15:16:53 - INFO: Mini batch Iter: 32 train_loss= 11.40058 graph_loss= 11.31639 reg_loss= 0.08419
05/21/2022 15:16:56 - INFO: Mini batch Iter: 33 train_loss= 10.32298 graph_loss= 10.23876 reg_loss= 0.08422
05/21/2022 15:16:58 - INFO: Mini batch Iter: 34 train_loss= 10.46889 graph_loss= 10.38461 reg_loss= 0.08428
05/21/2022 15:17:01 - INFO: Mini batch Iter: 35 train_loss= 11.41190 graph_loss= 11.32755 reg_loss= 0.08435
05/21/2022 15:17:03 - INFO: Mini batch Iter: 36 train_loss= 10.65347 graph_loss= 10.56905 reg_loss= 0.08441
05/21/2022 15:17:07 - INFO: Mini batch Iter: 37 train_loss= 11.07047 graph_loss= 10.98598 reg_loss= 0.08448
05/21/2022 15:17:09 - INFO: Mini batch Iter: 38 train_loss= 10.68472 graph_loss= 10.60020 reg_loss= 0.08452
05/21/2022 15:17:11 - INFO: Mini batch Iter: 39 train_loss= 10.75804 graph_loss= 10.67350 reg_loss= 0.08455
05/21/2022 15:17:11 - INFO: Time for epoch : 74.81004691123962
05/21/2022 15:24:03 - INFO: Test results at epoch 1: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E3A60>, {'operator_hadamard': [0.9618115174854844, 0.9618115174854844]}) best is : operator_hadamard 0.9618115174854844
05/21/2022 15:24:06 - INFO: Mini batch Iter: 0 train_loss= 11.67574 graph_loss= 11.59118 reg_loss= 0.08456
05/21/2022 15:24:09 - INFO: Mini batch Iter: 1 train_loss= 10.86819 graph_loss= 10.78363 reg_loss= 0.08456
05/21/2022 15:24:12 - INFO: Mini batch Iter: 2 train_loss= 10.58688 graph_loss= 10.50232 reg_loss= 0.08456
05/21/2022 15:24:14 - INFO: Mini batch Iter: 3 train_loss= 10.66529 graph_loss= 10.58070 reg_loss= 0.08459
05/21/2022 15:24:17 - INFO: Mini batch Iter: 4 train_loss= 10.85715 graph_loss= 10.77252 reg_loss= 0.08463
05/21/2022 15:24:21 - INFO: Mini batch Iter: 5 train_loss= 10.57523 graph_loss= 10.49057 reg_loss= 0.08466
05/21/2022 15:24:23 - INFO: Mini batch Iter: 6 train_loss= 10.75822 graph_loss= 10.67351 reg_loss= 0.08471
05/21/2022 15:24:26 - INFO: Mini batch Iter: 7 train_loss= 10.78522 graph_loss= 10.70046 reg_loss= 0.08476
05/21/2022 15:24:29 - INFO: Mini batch Iter: 8 train_loss= 10.53615 graph_loss= 10.45138 reg_loss= 0.08477
05/21/2022 15:24:31 - INFO: Mini batch Iter: 9 train_loss= 11.36132 graph_loss= 11.27652 reg_loss= 0.08480
05/21/2022 15:24:35 - INFO: Mini batch Iter: 10 train_loss= 11.81478 graph_loss= 11.72995 reg_loss= 0.08483
05/21/2022 15:24:38 - INFO: Mini batch Iter: 11 train_loss= 10.66399 graph_loss= 10.57912 reg_loss= 0.08487
05/21/2022 15:24:40 - INFO: Mini batch Iter: 12 train_loss= 10.44804 graph_loss= 10.36315 reg_loss= 0.08489
05/21/2022 15:24:43 - INFO: Mini batch Iter: 13 train_loss= 10.41952 graph_loss= 10.33460 reg_loss= 0.08492
05/21/2022 15:24:46 - INFO: Mini batch Iter: 14 train_loss= 10.87240 graph_loss= 10.78744 reg_loss= 0.08496
05/21/2022 15:24:48 - INFO: Mini batch Iter: 15 train_loss= 10.74598 graph_loss= 10.66097 reg_loss= 0.08501
05/21/2022 15:24:51 - INFO: Mini batch Iter: 16 train_loss= 10.52851 graph_loss= 10.44345 reg_loss= 0.08505
05/21/2022 15:24:54 - INFO: Mini batch Iter: 17 train_loss= 10.55514 graph_loss= 10.47003 reg_loss= 0.08511
05/21/2022 15:24:57 - INFO: Mini batch Iter: 18 train_loss= 10.39945 graph_loss= 10.31428 reg_loss= 0.08517
05/21/2022 15:24:59 - INFO: Mini batch Iter: 19 train_loss= 10.72371 graph_loss= 10.63847 reg_loss= 0.08524
05/21/2022 15:25:02 - INFO: Mini batch Iter: 20 train_loss= 11.03083 graph_loss= 10.94551 reg_loss= 0.08533
05/21/2022 15:25:06 - INFO: Mini batch Iter: 21 train_loss= 10.95122 graph_loss= 10.86582 reg_loss= 0.08539
05/21/2022 15:25:08 - INFO: Mini batch Iter: 22 train_loss= 10.38015 graph_loss= 10.29472 reg_loss= 0.08543
05/21/2022 15:25:11 - INFO: Mini batch Iter: 23 train_loss= 10.74186 graph_loss= 10.65637 reg_loss= 0.08549
05/21/2022 15:25:14 - INFO: Mini batch Iter: 24 train_loss= 10.45730 graph_loss= 10.37175 reg_loss= 0.08555
05/21/2022 15:25:16 - INFO: Mini batch Iter: 25 train_loss= 10.85292 graph_loss= 10.76729 reg_loss= 0.08563
05/21/2022 15:25:19 - INFO: Mini batch Iter: 26 train_loss= 10.77619 graph_loss= 10.69050 reg_loss= 0.08569
05/21/2022 15:25:22 - INFO: Mini batch Iter: 27 train_loss= 10.99679 graph_loss= 10.91102 reg_loss= 0.08577
05/21/2022 15:25:24 - INFO: Mini batch Iter: 28 train_loss= 10.79474 graph_loss= 10.70894 reg_loss= 0.08581
05/21/2022 15:25:27 - INFO: Mini batch Iter: 29 train_loss= 10.67776 graph_loss= 10.59192 reg_loss= 0.08584
05/21/2022 15:25:30 - INFO: Mini batch Iter: 30 train_loss= 10.66446 graph_loss= 10.57858 reg_loss= 0.08588
05/21/2022 15:25:33 - INFO: Mini batch Iter: 31 train_loss= 10.58954 graph_loss= 10.50363 reg_loss= 0.08591
05/21/2022 15:25:36 - INFO: Mini batch Iter: 32 train_loss= 10.59389 graph_loss= 10.50795 reg_loss= 0.08594
05/21/2022 15:25:38 - INFO: Mini batch Iter: 33 train_loss= 10.70638 graph_loss= 10.62041 reg_loss= 0.08597
05/21/2022 15:25:41 - INFO: Mini batch Iter: 34 train_loss= 10.52840 graph_loss= 10.44239 reg_loss= 0.08601
05/21/2022 15:25:43 - INFO: Mini batch Iter: 35 train_loss= 10.58965 graph_loss= 10.50357 reg_loss= 0.08608
05/21/2022 15:25:46 - INFO: Mini batch Iter: 36 train_loss= 10.92972 graph_loss= 10.84357 reg_loss= 0.08615
05/21/2022 15:25:48 - INFO: Mini batch Iter: 37 train_loss= 10.89382 graph_loss= 10.80760 reg_loss= 0.08622
05/21/2022 15:25:51 - INFO: Mini batch Iter: 38 train_loss= 10.51097 graph_loss= 10.42467 reg_loss= 0.08630
05/21/2022 15:25:53 - INFO: Mini batch Iter: 39 train_loss= 10.87943 graph_loss= 10.79304 reg_loss= 0.08639
05/21/2022 15:25:53 - INFO: Time for epoch : 75.59014010429382
05/21/2022 15:33:38 - INFO: Test results at epoch 2: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689ECF28>, {'operator_hadamard': [0.9663174242030407, 0.9663174242030407]}) best is : operator_hadamard 0.9663174242030407
05/21/2022 15:33:40 - INFO: Mini batch Iter: 0 train_loss= 10.45102 graph_loss= 10.36455 reg_loss= 0.08648
05/21/2022 15:33:43 - INFO: Mini batch Iter: 1 train_loss= 10.86370 graph_loss= 10.77712 reg_loss= 0.08657
05/21/2022 15:33:46 - INFO: Mini batch Iter: 2 train_loss= 10.55757 graph_loss= 10.47094 reg_loss= 0.08663
05/21/2022 15:33:49 - INFO: Mini batch Iter: 3 train_loss= 10.62133 graph_loss= 10.53465 reg_loss= 0.08668
05/21/2022 15:33:51 - INFO: Mini batch Iter: 4 train_loss= 10.49404 graph_loss= 10.40731 reg_loss= 0.08673
05/21/2022 15:33:54 - INFO: Mini batch Iter: 5 train_loss= 10.84105 graph_loss= 10.75426 reg_loss= 0.08680
05/21/2022 15:33:57 - INFO: Mini batch Iter: 6 train_loss= 11.11738 graph_loss= 11.03052 reg_loss= 0.08686
05/21/2022 15:34:00 - INFO: Mini batch Iter: 7 train_loss= 10.60938 graph_loss= 10.52245 reg_loss= 0.08692
05/21/2022 15:34:03 - INFO: Mini batch Iter: 8 train_loss= 10.83499 graph_loss= 10.74804 reg_loss= 0.08696
05/21/2022 15:34:06 - INFO: Mini batch Iter: 9 train_loss= 10.42288 graph_loss= 10.33589 reg_loss= 0.08699
05/21/2022 15:34:08 - INFO: Mini batch Iter: 10 train_loss= 10.48493 graph_loss= 10.39791 reg_loss= 0.08703
05/21/2022 15:34:10 - INFO: Mini batch Iter: 11 train_loss= 10.47277 graph_loss= 10.38568 reg_loss= 0.08709
05/21/2022 15:34:13 - INFO: Mini batch Iter: 12 train_loss= 10.50719 graph_loss= 10.42001 reg_loss= 0.08718
05/21/2022 15:34:16 - INFO: Mini batch Iter: 13 train_loss= 10.72721 graph_loss= 10.63995 reg_loss= 0.08726
05/21/2022 15:34:18 - INFO: Mini batch Iter: 14 train_loss= 10.65826 graph_loss= 10.57093 reg_loss= 0.08733
05/21/2022 15:34:21 - INFO: Mini batch Iter: 15 train_loss= 10.52721 graph_loss= 10.43981 reg_loss= 0.08740
05/21/2022 15:34:25 - INFO: Mini batch Iter: 16 train_loss= 10.70803 graph_loss= 10.62059 reg_loss= 0.08744
05/21/2022 15:34:27 - INFO: Mini batch Iter: 17 train_loss= 10.47755 graph_loss= 10.39009 reg_loss= 0.08746
05/21/2022 15:34:30 - INFO: Mini batch Iter: 18 train_loss= 10.45432 graph_loss= 10.36682 reg_loss= 0.08750
05/21/2022 15:34:33 - INFO: Mini batch Iter: 19 train_loss= 10.77620 graph_loss= 10.68863 reg_loss= 0.08756
05/21/2022 15:34:36 - INFO: Mini batch Iter: 20 train_loss= 10.51279 graph_loss= 10.42520 reg_loss= 0.08759
05/21/2022 15:34:38 - INFO: Mini batch Iter: 21 train_loss= 11.02142 graph_loss= 10.93381 reg_loss= 0.08761
05/21/2022 15:34:41 - INFO: Mini batch Iter: 22 train_loss= 10.73835 graph_loss= 10.65072 reg_loss= 0.08763
05/21/2022 15:34:44 - INFO: Mini batch Iter: 23 train_loss= 10.98169 graph_loss= 10.89407 reg_loss= 0.08763
05/21/2022 15:34:47 - INFO: Mini batch Iter: 24 train_loss= 10.73187 graph_loss= 10.64425 reg_loss= 0.08762
05/21/2022 15:34:49 - INFO: Mini batch Iter: 25 train_loss= 10.81663 graph_loss= 10.72902 reg_loss= 0.08762
05/21/2022 15:34:52 - INFO: Mini batch Iter: 26 train_loss= 10.86508 graph_loss= 10.77747 reg_loss= 0.08761
05/21/2022 15:34:55 - INFO: Mini batch Iter: 27 train_loss= 11.28460 graph_loss= 11.19697 reg_loss= 0.08762
05/21/2022 15:34:57 - INFO: Mini batch Iter: 28 train_loss= 10.69718 graph_loss= 10.60954 reg_loss= 0.08764
05/21/2022 15:35:00 - INFO: Mini batch Iter: 29 train_loss= 10.57886 graph_loss= 10.49121 reg_loss= 0.08765
05/21/2022 15:35:02 - INFO: Mini batch Iter: 30 train_loss= 10.82313 graph_loss= 10.73545 reg_loss= 0.08767
05/21/2022 15:35:05 - INFO: Mini batch Iter: 31 train_loss= 10.39151 graph_loss= 10.30380 reg_loss= 0.08771
05/21/2022 15:35:08 - INFO: Mini batch Iter: 32 train_loss= 10.61775 graph_loss= 10.52997 reg_loss= 0.08778
05/21/2022 15:35:12 - INFO: Mini batch Iter: 33 train_loss= 10.61275 graph_loss= 10.52487 reg_loss= 0.08787
05/21/2022 15:35:15 - INFO: Mini batch Iter: 34 train_loss= 10.40818 graph_loss= 10.32025 reg_loss= 0.08793
05/21/2022 15:35:17 - INFO: Mini batch Iter: 35 train_loss= 10.32625 graph_loss= 10.23825 reg_loss= 0.08800
05/21/2022 15:35:21 - INFO: Mini batch Iter: 36 train_loss= 10.45864 graph_loss= 10.37051 reg_loss= 0.08813
05/21/2022 15:35:23 - INFO: Mini batch Iter: 37 train_loss= 10.52085 graph_loss= 10.43259 reg_loss= 0.08826
05/21/2022 15:35:26 - INFO: Mini batch Iter: 38 train_loss= 10.54181 graph_loss= 10.45343 reg_loss= 0.08838
05/21/2022 15:35:28 - INFO: Mini batch Iter: 39 train_loss= 10.08251 graph_loss= 9.99400 reg_loss= 0.08850
05/21/2022 15:35:28 - INFO: Time for epoch : 75.96828985214233
05/21/2022 15:43:00 - INFO: Test results at epoch 3: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E61E0>, {'operator_hadamard': [0.9721505833365562, 0.9721505833365562]}) best is : operator_hadamard 0.9721505833365562
05/21/2022 15:43:02 - INFO: Mini batch Iter: 0 train_loss= 10.55145 graph_loss= 10.46281 reg_loss= 0.08864
05/21/2022 15:43:05 - INFO: Mini batch Iter: 1 train_loss= 10.83209 graph_loss= 10.74329 reg_loss= 0.08880
05/21/2022 15:43:08 - INFO: Mini batch Iter: 2 train_loss= 11.00079 graph_loss= 10.91185 reg_loss= 0.08894
05/21/2022 15:43:11 - INFO: Mini batch Iter: 3 train_loss= 10.61265 graph_loss= 10.52360 reg_loss= 0.08905
05/21/2022 15:43:13 - INFO: Mini batch Iter: 4 train_loss= 10.82527 graph_loss= 10.73610 reg_loss= 0.08917
05/21/2022 15:43:16 - INFO: Mini batch Iter: 5 train_loss= 10.34853 graph_loss= 10.25926 reg_loss= 0.08927
05/21/2022 15:43:19 - INFO: Mini batch Iter: 6 train_loss= 10.73133 graph_loss= 10.64196 reg_loss= 0.08937
05/21/2022 15:43:22 - INFO: Mini batch Iter: 7 train_loss= 10.59034 graph_loss= 10.50089 reg_loss= 0.08946
05/21/2022 15:43:25 - INFO: Mini batch Iter: 8 train_loss= 10.53661 graph_loss= 10.44707 reg_loss= 0.08954
05/21/2022 15:43:27 - INFO: Mini batch Iter: 9 train_loss= 10.74298 graph_loss= 10.65336 reg_loss= 0.08963
05/21/2022 15:43:30 - INFO: Mini batch Iter: 10 train_loss= 10.71975 graph_loss= 10.63004 reg_loss= 0.08971
05/21/2022 15:43:32 - INFO: Mini batch Iter: 11 train_loss= 10.50551 graph_loss= 10.41570 reg_loss= 0.08981
05/21/2022 15:43:35 - INFO: Mini batch Iter: 12 train_loss= 10.48052 graph_loss= 10.39059 reg_loss= 0.08993
05/21/2022 15:43:38 - INFO: Mini batch Iter: 13 train_loss= 10.85728 graph_loss= 10.76720 reg_loss= 0.09008
05/21/2022 15:43:40 - INFO: Mini batch Iter: 14 train_loss= 10.43719 graph_loss= 10.34701 reg_loss= 0.09018
05/21/2022 15:43:43 - INFO: Mini batch Iter: 15 train_loss= 10.52329 graph_loss= 10.43297 reg_loss= 0.09031
05/21/2022 15:43:46 - INFO: Mini batch Iter: 16 train_loss= 10.70272 graph_loss= 10.61226 reg_loss= 0.09046
05/21/2022 15:43:48 - INFO: Mini batch Iter: 17 train_loss= 10.55797 graph_loss= 10.46738 reg_loss= 0.09060
05/21/2022 15:43:52 - INFO: Mini batch Iter: 18 train_loss= 10.98240 graph_loss= 10.89167 reg_loss= 0.09073
05/21/2022 15:43:54 - INFO: Mini batch Iter: 19 train_loss= 10.48263 graph_loss= 10.39180 reg_loss= 0.09083
05/21/2022 15:43:57 - INFO: Mini batch Iter: 20 train_loss= 10.42388 graph_loss= 10.33294 reg_loss= 0.09094
05/21/2022 15:44:00 - INFO: Mini batch Iter: 21 train_loss= 10.31446 graph_loss= 10.22339 reg_loss= 0.09107
05/21/2022 15:44:02 - INFO: Mini batch Iter: 22 train_loss= 10.37532 graph_loss= 10.28409 reg_loss= 0.09123
05/21/2022 15:44:05 - INFO: Mini batch Iter: 23 train_loss= 10.65218 graph_loss= 10.56077 reg_loss= 0.09141
05/21/2022 15:44:09 - INFO: Mini batch Iter: 24 train_loss= 10.49674 graph_loss= 10.40514 reg_loss= 0.09160
05/21/2022 15:44:11 - INFO: Mini batch Iter: 25 train_loss= 10.58178 graph_loss= 10.48997 reg_loss= 0.09181
05/21/2022 15:44:14 - INFO: Mini batch Iter: 26 train_loss= 10.51082 graph_loss= 10.41880 reg_loss= 0.09202
05/21/2022 15:44:17 - INFO: Mini batch Iter: 27 train_loss= 10.83064 graph_loss= 10.73843 reg_loss= 0.09220
05/21/2022 15:44:19 - INFO: Mini batch Iter: 28 train_loss= 10.67969 graph_loss= 10.58731 reg_loss= 0.09237
05/21/2022 15:44:23 - INFO: Mini batch Iter: 29 train_loss= 10.80897 graph_loss= 10.71642 reg_loss= 0.09255
05/21/2022 15:44:26 - INFO: Mini batch Iter: 30 train_loss= 10.14887 graph_loss= 10.05620 reg_loss= 0.09267
05/21/2022 15:44:28 - INFO: Mini batch Iter: 31 train_loss= 10.09898 graph_loss= 10.00617 reg_loss= 0.09281
05/21/2022 15:44:31 - INFO: Mini batch Iter: 32 train_loss= 10.38515 graph_loss= 10.29214 reg_loss= 0.09300
05/21/2022 15:44:33 - INFO: Mini batch Iter: 33 train_loss= 10.32171 graph_loss= 10.22851 reg_loss= 0.09320
05/21/2022 15:44:36 - INFO: Mini batch Iter: 34 train_loss= 10.98822 graph_loss= 10.89479 reg_loss= 0.09343
05/21/2022 15:44:39 - INFO: Mini batch Iter: 35 train_loss= 10.63409 graph_loss= 10.54043 reg_loss= 0.09366
05/21/2022 15:44:41 - INFO: Mini batch Iter: 36 train_loss= 10.69823 graph_loss= 10.60435 reg_loss= 0.09388
05/21/2022 15:44:44 - INFO: Mini batch Iter: 37 train_loss= 10.49090 graph_loss= 10.39682 reg_loss= 0.09408
05/21/2022 15:44:47 - INFO: Mini batch Iter: 38 train_loss= 10.68709 graph_loss= 10.59282 reg_loss= 0.09427
05/21/2022 15:44:49 - INFO: Mini batch Iter: 39 train_loss= 10.87592 graph_loss= 10.78150 reg_loss= 0.09442
05/21/2022 15:44:49 - INFO: Time for epoch : 75.08615756034851
05/21/2022 15:52:06 - INFO: Test results at epoch 4: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E6510>, {'operator_hadamard': [0.9732802724793906, 0.9732802724793906]}) best is : operator_hadamard 0.9732802724793906
05/21/2022 15:52:09 - INFO: Mini batch Iter: 0 train_loss= 10.31827 graph_loss= 10.22370 reg_loss= 0.09457
05/21/2022 15:52:12 - INFO: Mini batch Iter: 1 train_loss= 10.96821 graph_loss= 10.87349 reg_loss= 0.09472
05/21/2022 15:52:14 - INFO: Mini batch Iter: 2 train_loss= 10.75388 graph_loss= 10.65900 reg_loss= 0.09488
05/21/2022 15:52:17 - INFO: Mini batch Iter: 3 train_loss= 10.36883 graph_loss= 10.27382 reg_loss= 0.09501
05/21/2022 15:52:20 - INFO: Mini batch Iter: 4 train_loss= 10.76834 graph_loss= 10.67319 reg_loss= 0.09516
05/21/2022 15:52:22 - INFO: Mini batch Iter: 5 train_loss= 10.63241 graph_loss= 10.53716 reg_loss= 0.09525
05/21/2022 15:52:26 - INFO: Mini batch Iter: 6 train_loss= 10.67246 graph_loss= 10.57712 reg_loss= 0.09534
05/21/2022 15:52:29 - INFO: Mini batch Iter: 7 train_loss= 10.73757 graph_loss= 10.64216 reg_loss= 0.09541
05/21/2022 15:52:31 - INFO: Mini batch Iter: 8 train_loss= 10.42676 graph_loss= 10.33131 reg_loss= 0.09546
05/21/2022 15:52:34 - INFO: Mini batch Iter: 9 train_loss= 10.68511 graph_loss= 10.58959 reg_loss= 0.09552
05/21/2022 15:52:37 - INFO: Mini batch Iter: 10 train_loss= 10.63763 graph_loss= 10.54205 reg_loss= 0.09558
05/21/2022 15:52:40 - INFO: Mini batch Iter: 11 train_loss= 10.32793 graph_loss= 10.23232 reg_loss= 0.09561
05/21/2022 15:52:42 - INFO: Mini batch Iter: 12 train_loss= 10.56634 graph_loss= 10.47067 reg_loss= 0.09567
05/21/2022 15:52:45 - INFO: Mini batch Iter: 13 train_loss= 10.68569 graph_loss= 10.58994 reg_loss= 0.09575
05/21/2022 15:52:48 - INFO: Mini batch Iter: 14 train_loss= 10.34000 graph_loss= 10.24414 reg_loss= 0.09585
05/21/2022 15:52:51 - INFO: Mini batch Iter: 15 train_loss= 10.51833 graph_loss= 10.42236 reg_loss= 0.09597
05/21/2022 15:52:53 - INFO: Mini batch Iter: 16 train_loss= 11.79728 graph_loss= 11.70120 reg_loss= 0.09608
05/21/2022 15:52:57 - INFO: Mini batch Iter: 17 train_loss= 10.59312 graph_loss= 10.49693 reg_loss= 0.09619
05/21/2022 15:52:59 - INFO: Mini batch Iter: 18 train_loss= 10.10930 graph_loss= 10.01300 reg_loss= 0.09630
05/21/2022 15:53:02 - INFO: Mini batch Iter: 19 train_loss= 10.40186 graph_loss= 10.30541 reg_loss= 0.09645
05/21/2022 15:53:06 - INFO: Mini batch Iter: 20 train_loss= 11.18782 graph_loss= 11.09119 reg_loss= 0.09663
05/21/2022 15:53:08 - INFO: Mini batch Iter: 21 train_loss= 10.15576 graph_loss= 10.05898 reg_loss= 0.09679
05/21/2022 15:53:12 - INFO: Mini batch Iter: 22 train_loss= 10.64361 graph_loss= 10.54660 reg_loss= 0.09701
05/21/2022 15:53:14 - INFO: Mini batch Iter: 23 train_loss= 10.50189 graph_loss= 10.40467 reg_loss= 0.09722
05/21/2022 15:53:17 - INFO: Mini batch Iter: 24 train_loss= 10.66999 graph_loss= 10.57257 reg_loss= 0.09742
05/21/2022 15:53:20 - INFO: Mini batch Iter: 25 train_loss= 10.61454 graph_loss= 10.51693 reg_loss= 0.09761
05/21/2022 15:53:22 - INFO: Mini batch Iter: 26 train_loss= 10.34450 graph_loss= 10.24670 reg_loss= 0.09780
05/21/2022 15:53:25 - INFO: Mini batch Iter: 27 train_loss= 10.71009 graph_loss= 10.61207 reg_loss= 0.09802
05/21/2022 15:53:27 - INFO: Mini batch Iter: 28 train_loss= 10.72328 graph_loss= 10.62504 reg_loss= 0.09824
05/21/2022 15:53:30 - INFO: Mini batch Iter: 29 train_loss= 10.49802 graph_loss= 10.39958 reg_loss= 0.09845
05/21/2022 15:53:33 - INFO: Mini batch Iter: 30 train_loss= 10.75182 graph_loss= 10.65318 reg_loss= 0.09865
05/21/2022 15:53:36 - INFO: Mini batch Iter: 31 train_loss= 10.55737 graph_loss= 10.45856 reg_loss= 0.09881
05/21/2022 15:53:38 - INFO: Mini batch Iter: 32 train_loss= 10.39003 graph_loss= 10.29106 reg_loss= 0.09897
05/21/2022 15:53:41 - INFO: Mini batch Iter: 33 train_loss= 10.79079 graph_loss= 10.69164 reg_loss= 0.09914
05/21/2022 15:53:43 - INFO: Mini batch Iter: 34 train_loss= 10.63777 graph_loss= 10.53849 reg_loss= 0.09928
05/21/2022 15:53:46 - INFO: Mini batch Iter: 35 train_loss= 10.43519 graph_loss= 10.33575 reg_loss= 0.09943
05/21/2022 15:53:48 - INFO: Mini batch Iter: 36 train_loss= 10.53687 graph_loss= 10.43726 reg_loss= 0.09961
05/21/2022 15:53:51 - INFO: Mini batch Iter: 37 train_loss= 10.47962 graph_loss= 10.37983 reg_loss= 0.09979
05/21/2022 15:53:53 - INFO: Mini batch Iter: 38 train_loss= 10.45908 graph_loss= 10.35909 reg_loss= 0.09999
05/21/2022 15:53:55 - INFO: Mini batch Iter: 39 train_loss= 11.17324 graph_loss= 11.07304 reg_loss= 0.10020
05/21/2022 15:53:55 - INFO: Time for epoch : 75.1704490184784
05/21/2022 16:01:50 - INFO: Test results at epoch 5: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B561A05AE8>, {'operator_hadamard': [0.9729063255215782, 0.9729063255215782]}) best is : operator_hadamard 0.9729063255215782
05/21/2022 16:01:53 - INFO: Mini batch Iter: 0 train_loss= 10.54642 graph_loss= 10.44601 reg_loss= 0.10041
05/21/2022 16:01:55 - INFO: Mini batch Iter: 1 train_loss= 10.40362 graph_loss= 10.30301 reg_loss= 0.10061
05/21/2022 16:01:58 - INFO: Mini batch Iter: 2 train_loss= 10.78920 graph_loss= 10.68837 reg_loss= 0.10083
05/21/2022 16:02:01 - INFO: Mini batch Iter: 3 train_loss= 10.52192 graph_loss= 10.42089 reg_loss= 0.10103
05/21/2022 16:02:04 - INFO: Mini batch Iter: 4 train_loss= 10.64022 graph_loss= 10.53899 reg_loss= 0.10123
05/21/2022 16:02:06 - INFO: Mini batch Iter: 5 train_loss= 10.49389 graph_loss= 10.39246 reg_loss= 0.10143
05/21/2022 16:02:09 - INFO: Mini batch Iter: 6 train_loss= 10.30189 graph_loss= 10.20028 reg_loss= 0.10162
05/21/2022 16:02:12 - INFO: Mini batch Iter: 7 train_loss= 10.64568 graph_loss= 10.54384 reg_loss= 0.10184
05/21/2022 16:02:14 - INFO: Mini batch Iter: 8 train_loss= 10.50391 graph_loss= 10.40185 reg_loss= 0.10206
05/21/2022 16:02:18 - INFO: Mini batch Iter: 9 train_loss= 10.72574 graph_loss= 10.62345 reg_loss= 0.10228
05/21/2022 16:02:20 - INFO: Mini batch Iter: 10 train_loss= 10.37050 graph_loss= 10.26801 reg_loss= 0.10249
05/21/2022 16:02:23 - INFO: Mini batch Iter: 11 train_loss= 10.47923 graph_loss= 10.37651 reg_loss= 0.10272
05/21/2022 16:02:26 - INFO: Mini batch Iter: 12 train_loss= 10.37569 graph_loss= 10.27276 reg_loss= 0.10293
05/21/2022 16:02:29 - INFO: Mini batch Iter: 13 train_loss= 10.88219 graph_loss= 10.77903 reg_loss= 0.10316
05/21/2022 16:02:32 - INFO: Mini batch Iter: 14 train_loss= 10.39298 graph_loss= 10.28960 reg_loss= 0.10338
05/21/2022 16:02:35 - INFO: Mini batch Iter: 15 train_loss= 10.45441 graph_loss= 10.35083 reg_loss= 0.10359
05/21/2022 16:02:37 - INFO: Mini batch Iter: 16 train_loss= 10.70295 graph_loss= 10.59917 reg_loss= 0.10378
05/21/2022 16:02:40 - INFO: Mini batch Iter: 17 train_loss= 10.37703 graph_loss= 10.27306 reg_loss= 0.10397
05/21/2022 16:02:42 - INFO: Mini batch Iter: 18 train_loss= 10.71836 graph_loss= 10.61421 reg_loss= 0.10414
05/21/2022 16:02:45 - INFO: Mini batch Iter: 19 train_loss= 10.35440 graph_loss= 10.25010 reg_loss= 0.10430
05/21/2022 16:02:48 - INFO: Mini batch Iter: 20 train_loss= 10.52766 graph_loss= 10.42321 reg_loss= 0.10445
05/21/2022 16:02:50 - INFO: Mini batch Iter: 21 train_loss= 11.11365 graph_loss= 11.00905 reg_loss= 0.10460
05/21/2022 16:02:53 - INFO: Mini batch Iter: 22 train_loss= 10.57207 graph_loss= 10.46733 reg_loss= 0.10474
05/21/2022 16:02:55 - INFO: Mini batch Iter: 23 train_loss= 10.63117 graph_loss= 10.52629 reg_loss= 0.10487
05/21/2022 16:02:59 - INFO: Mini batch Iter: 24 train_loss= 10.84611 graph_loss= 10.74111 reg_loss= 0.10500
05/21/2022 16:03:02 - INFO: Mini batch Iter: 25 train_loss= 10.40963 graph_loss= 10.30450 reg_loss= 0.10513
05/21/2022 16:03:05 - INFO: Mini batch Iter: 26 train_loss= 10.65421 graph_loss= 10.54898 reg_loss= 0.10523
05/21/2022 16:03:07 - INFO: Mini batch Iter: 27 train_loss= 10.50577 graph_loss= 10.40048 reg_loss= 0.10529
05/21/2022 16:03:10 - INFO: Mini batch Iter: 28 train_loss= 10.86636 graph_loss= 10.76102 reg_loss= 0.10534
05/21/2022 16:03:13 - INFO: Mini batch Iter: 29 train_loss= 10.75906 graph_loss= 10.65367 reg_loss= 0.10539
05/21/2022 16:03:15 - INFO: Mini batch Iter: 30 train_loss= 10.24455 graph_loss= 10.13914 reg_loss= 0.10541
05/21/2022 16:03:18 - INFO: Mini batch Iter: 31 train_loss= 10.43893 graph_loss= 10.33347 reg_loss= 0.10546
05/21/2022 16:03:21 - INFO: Mini batch Iter: 32 train_loss= 10.67910 graph_loss= 10.57356 reg_loss= 0.10554
05/21/2022 16:03:23 - INFO: Mini batch Iter: 33 train_loss= 10.49598 graph_loss= 10.39037 reg_loss= 0.10561
05/21/2022 16:03:26 - INFO: Mini batch Iter: 34 train_loss= 10.36233 graph_loss= 10.25662 reg_loss= 0.10571
05/21/2022 16:03:28 - INFO: Mini batch Iter: 35 train_loss= 10.18981 graph_loss= 10.08398 reg_loss= 0.10583
05/21/2022 16:03:31 - INFO: Mini batch Iter: 36 train_loss= 10.52235 graph_loss= 10.41635 reg_loss= 0.10600
05/21/2022 16:03:33 - INFO: Mini batch Iter: 37 train_loss= 10.30381 graph_loss= 10.19762 reg_loss= 0.10619
05/21/2022 16:03:37 - INFO: Mini batch Iter: 38 train_loss= 10.94602 graph_loss= 10.83963 reg_loss= 0.10639
05/21/2022 16:03:39 - INFO: Mini batch Iter: 39 train_loss= 10.43675 graph_loss= 10.33020 reg_loss= 0.10655
05/21/2022 16:03:39 - INFO: Time for epoch : 75.31890487670898
05/21/2022 16:11:19 - INFO: Test results at epoch 6: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E3D08>, {'operator_hadamard': [0.9737346459847966, 0.9737346459847966]}) best is : operator_hadamard 0.9737346459847966
05/21/2022 16:11:21 - INFO: Mini batch Iter: 0 train_loss= 10.28757 graph_loss= 10.18085 reg_loss= 0.10672
05/21/2022 16:11:24 - INFO: Mini batch Iter: 1 train_loss= 10.53223 graph_loss= 10.42531 reg_loss= 0.10692
05/21/2022 16:11:27 - INFO: Mini batch Iter: 2 train_loss= 10.89241 graph_loss= 10.78529 reg_loss= 0.10711
05/21/2022 16:11:29 - INFO: Mini batch Iter: 3 train_loss= 10.26885 graph_loss= 10.16159 reg_loss= 0.10726
05/21/2022 16:11:32 - INFO: Mini batch Iter: 4 train_loss= 10.21145 graph_loss= 10.10404 reg_loss= 0.10741
05/21/2022 16:11:35 - INFO: Mini batch Iter: 5 train_loss= 10.61766 graph_loss= 10.51010 reg_loss= 0.10756
05/21/2022 16:11:37 - INFO: Mini batch Iter: 6 train_loss= 10.51280 graph_loss= 10.40509 reg_loss= 0.10771
05/21/2022 16:11:40 - INFO: Mini batch Iter: 7 train_loss= 10.17454 graph_loss= 10.06666 reg_loss= 0.10788
05/21/2022 16:11:42 - INFO: Mini batch Iter: 8 train_loss= 10.37467 graph_loss= 10.26659 reg_loss= 0.10807
05/21/2022 16:11:45 - INFO: Mini batch Iter: 9 train_loss= 10.87465 graph_loss= 10.76639 reg_loss= 0.10827
05/21/2022 16:11:47 - INFO: Mini batch Iter: 10 train_loss= 10.32200 graph_loss= 10.21355 reg_loss= 0.10845
05/21/2022 16:11:50 - INFO: Mini batch Iter: 11 train_loss= 10.49845 graph_loss= 10.38980 reg_loss= 0.10864
05/21/2022 16:11:53 - INFO: Mini batch Iter: 12 train_loss= 11.12345 graph_loss= 11.01462 reg_loss= 0.10883
05/21/2022 16:11:56 - INFO: Mini batch Iter: 13 train_loss= 10.83956 graph_loss= 10.73060 reg_loss= 0.10896
05/21/2022 16:11:58 - INFO: Mini batch Iter: 14 train_loss= 10.82292 graph_loss= 10.71385 reg_loss= 0.10908
05/21/2022 16:12:01 - INFO: Mini batch Iter: 15 train_loss= 10.31193 graph_loss= 10.20274 reg_loss= 0.10918
05/21/2022 16:12:05 - INFO: Mini batch Iter: 16 train_loss= 10.61927 graph_loss= 10.50996 reg_loss= 0.10931
05/21/2022 16:12:07 - INFO: Mini batch Iter: 17 train_loss= 10.45215 graph_loss= 10.34269 reg_loss= 0.10945
05/21/2022 16:12:10 - INFO: Mini batch Iter: 18 train_loss= 10.42173 graph_loss= 10.31213 reg_loss= 0.10960
05/21/2022 16:12:13 - INFO: Mini batch Iter: 19 train_loss= 10.38805 graph_loss= 10.27828 reg_loss= 0.10977
05/21/2022 16:12:15 - INFO: Mini batch Iter: 20 train_loss= 10.31219 graph_loss= 10.20223 reg_loss= 0.10996
05/21/2022 16:12:18 - INFO: Mini batch Iter: 21 train_loss= 10.41279 graph_loss= 10.30261 reg_loss= 0.11018
05/21/2022 16:12:20 - INFO: Mini batch Iter: 22 train_loss= 10.35149 graph_loss= 10.24106 reg_loss= 0.11043
05/21/2022 16:12:23 - INFO: Mini batch Iter: 23 train_loss= 10.30647 graph_loss= 10.19578 reg_loss= 0.11069
05/21/2022 16:12:25 - INFO: Mini batch Iter: 24 train_loss= 10.44236 graph_loss= 10.33140 reg_loss= 0.11096
05/21/2022 16:12:28 - INFO: Mini batch Iter: 25 train_loss= 10.38173 graph_loss= 10.27051 reg_loss= 0.11122
05/21/2022 16:12:31 - INFO: Mini batch Iter: 26 train_loss= 10.23990 graph_loss= 10.12844 reg_loss= 0.11146
05/21/2022 16:12:34 - INFO: Mini batch Iter: 27 train_loss= 10.36505 graph_loss= 10.25332 reg_loss= 0.11172
05/21/2022 16:12:36 - INFO: Mini batch Iter: 28 train_loss= 10.41474 graph_loss= 10.30274 reg_loss= 0.11200
05/21/2022 16:12:39 - INFO: Mini batch Iter: 29 train_loss= 10.52920 graph_loss= 10.41693 reg_loss= 0.11227
05/21/2022 16:12:42 - INFO: Mini batch Iter: 30 train_loss= 10.59322 graph_loss= 10.48070 reg_loss= 0.11252
05/21/2022 16:12:45 - INFO: Mini batch Iter: 31 train_loss= 10.68385 graph_loss= 10.57107 reg_loss= 0.11278
05/21/2022 16:12:48 - INFO: Mini batch Iter: 32 train_loss= 10.34567 graph_loss= 10.23269 reg_loss= 0.11298
05/21/2022 16:12:51 - INFO: Mini batch Iter: 33 train_loss= 10.22266 graph_loss= 10.10948 reg_loss= 0.11318
05/21/2022 16:12:54 - INFO: Mini batch Iter: 34 train_loss= 10.38604 graph_loss= 10.27264 reg_loss= 0.11340
05/21/2022 16:12:56 - INFO: Mini batch Iter: 35 train_loss= 10.49047 graph_loss= 10.37685 reg_loss= 0.11361
05/21/2022 16:13:00 - INFO: Mini batch Iter: 36 train_loss= 10.94725 graph_loss= 10.83348 reg_loss= 0.11377
05/21/2022 16:13:03 - INFO: Mini batch Iter: 37 train_loss= 10.78885 graph_loss= 10.67493 reg_loss= 0.11392
05/21/2022 16:13:07 - INFO: Mini batch Iter: 38 train_loss= 10.83347 graph_loss= 10.71940 reg_loss= 0.11406
05/21/2022 16:13:08 - INFO: Mini batch Iter: 39 train_loss= 10.36448 graph_loss= 10.25026 reg_loss= 0.11421
05/21/2022 16:13:08 - INFO: Time for epoch : 75.21486496925354
05/21/2022 16:20:55 - INFO: Test results at epoch 7: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B568A0ED08>, {'operator_hadamard': [0.9709376723912417, 0.9709376723912417]}) best is : operator_hadamard 0.9709376723912417
05/21/2022 16:20:57 - INFO: Mini batch Iter: 0 train_loss= 10.87209 graph_loss= 10.75772 reg_loss= 0.11437
05/21/2022 16:21:00 - INFO: Mini batch Iter: 1 train_loss= 10.35510 graph_loss= 10.24060 reg_loss= 0.11449
05/21/2022 16:21:03 - INFO: Mini batch Iter: 2 train_loss= 10.85030 graph_loss= 10.73565 reg_loss= 0.11465
05/21/2022 16:21:05 - INFO: Mini batch Iter: 3 train_loss= 10.30823 graph_loss= 10.19346 reg_loss= 0.11477
05/21/2022 16:21:08 - INFO: Mini batch Iter: 4 train_loss= 10.35481 graph_loss= 10.23989 reg_loss= 0.11492
05/21/2022 16:21:11 - INFO: Mini batch Iter: 5 train_loss= 10.28460 graph_loss= 10.16951 reg_loss= 0.11509
05/21/2022 16:21:13 - INFO: Mini batch Iter: 6 train_loss= 10.35483 graph_loss= 10.23955 reg_loss= 0.11528
05/21/2022 16:21:16 - INFO: Mini batch Iter: 7 train_loss= 10.44513 graph_loss= 10.32966 reg_loss= 0.11547
05/21/2022 16:21:18 - INFO: Mini batch Iter: 8 train_loss= 10.50824 graph_loss= 10.39257 reg_loss= 0.11567
05/21/2022 16:21:22 - INFO: Mini batch Iter: 9 train_loss= 10.47754 graph_loss= 10.36166 reg_loss= 0.11588
05/21/2022 16:21:25 - INFO: Mini batch Iter: 10 train_loss= 11.04530 graph_loss= 10.92924 reg_loss= 0.11607
05/21/2022 16:21:28 - INFO: Mini batch Iter: 11 train_loss= 10.19077 graph_loss= 10.07452 reg_loss= 0.11625
05/21/2022 16:21:31 - INFO: Mini batch Iter: 12 train_loss= 11.03143 graph_loss= 10.91498 reg_loss= 0.11645
05/21/2022 16:21:34 - INFO: Mini batch Iter: 13 train_loss= 10.47020 graph_loss= 10.35359 reg_loss= 0.11661
05/21/2022 16:21:37 - INFO: Mini batch Iter: 14 train_loss= 10.60343 graph_loss= 10.48666 reg_loss= 0.11677
05/21/2022 16:21:40 - INFO: Mini batch Iter: 15 train_loss= 10.34569 graph_loss= 10.22877 reg_loss= 0.11692
05/21/2022 16:21:43 - INFO: Mini batch Iter: 16 train_loss= 10.41932 graph_loss= 10.30223 reg_loss= 0.11709
05/21/2022 16:21:45 - INFO: Mini batch Iter: 17 train_loss= 10.69442 graph_loss= 10.57713 reg_loss= 0.11729
05/21/2022 16:21:48 - INFO: Mini batch Iter: 18 train_loss= 10.50529 graph_loss= 10.38783 reg_loss= 0.11746
05/21/2022 16:21:50 - INFO: Mini batch Iter: 19 train_loss= 10.24208 graph_loss= 10.12444 reg_loss= 0.11764
05/21/2022 16:21:53 - INFO: Mini batch Iter: 20 train_loss= 10.34416 graph_loss= 10.22629 reg_loss= 0.11787
05/21/2022 16:21:56 - INFO: Mini batch Iter: 21 train_loss= 10.34155 graph_loss= 10.22343 reg_loss= 0.11812
05/21/2022 16:21:58 - INFO: Mini batch Iter: 22 train_loss= 10.30951 graph_loss= 10.19115 reg_loss= 0.11835
05/21/2022 16:22:01 - INFO: Mini batch Iter: 23 train_loss= 10.84036 graph_loss= 10.72176 reg_loss= 0.11861
05/21/2022 16:22:03 - INFO: Mini batch Iter: 24 train_loss= 10.38132 graph_loss= 10.26250 reg_loss= 0.11882
05/21/2022 16:22:06 - INFO: Mini batch Iter: 25 train_loss= 10.47604 graph_loss= 10.35701 reg_loss= 0.11903
05/21/2022 16:22:09 - INFO: Mini batch Iter: 26 train_loss= 10.58955 graph_loss= 10.47031 reg_loss= 0.11923
05/21/2022 16:22:11 - INFO: Mini batch Iter: 27 train_loss= 10.38978 graph_loss= 10.27035 reg_loss= 0.11943
05/21/2022 16:22:14 - INFO: Mini batch Iter: 28 train_loss= 10.64120 graph_loss= 10.52158 reg_loss= 0.11962
05/21/2022 16:22:16 - INFO: Mini batch Iter: 29 train_loss= 10.40197 graph_loss= 10.28225 reg_loss= 0.11972
05/21/2022 16:22:19 - INFO: Mini batch Iter: 30 train_loss= 10.46303 graph_loss= 10.34322 reg_loss= 0.11981
05/21/2022 16:22:22 - INFO: Mini batch Iter: 31 train_loss= 10.31173 graph_loss= 10.19182 reg_loss= 0.11991
05/21/2022 16:22:25 - INFO: Mini batch Iter: 32 train_loss= 10.75888 graph_loss= 10.63885 reg_loss= 0.12003
05/21/2022 16:22:27 - INFO: Mini batch Iter: 33 train_loss= 10.52629 graph_loss= 10.40616 reg_loss= 0.12013
05/21/2022 16:22:30 - INFO: Mini batch Iter: 34 train_loss= 10.40098 graph_loss= 10.28075 reg_loss= 0.12024
05/21/2022 16:22:33 - INFO: Mini batch Iter: 35 train_loss= 10.41392 graph_loss= 10.29355 reg_loss= 0.12038
05/21/2022 16:22:35 - INFO: Mini batch Iter: 36 train_loss= 10.17023 graph_loss= 10.04971 reg_loss= 0.12053
05/21/2022 16:22:40 - INFO: Mini batch Iter: 37 train_loss= 10.68063 graph_loss= 10.55993 reg_loss= 0.12070
05/21/2022 16:22:43 - INFO: Mini batch Iter: 38 train_loss= 10.42597 graph_loss= 10.30518 reg_loss= 0.12079
05/21/2022 16:22:44 - INFO: Mini batch Iter: 39 train_loss= 10.46334 graph_loss= 10.34243 reg_loss= 0.12091
05/21/2022 16:22:44 - INFO: Time for epoch : 75.39055371284485
05/21/2022 16:30:10 - INFO: Test results at epoch 8: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E29D8>, {'operator_hadamard': [0.9702888310270582, 0.9702888310270582]}) best is : operator_hadamard 0.9702888310270582
05/21/2022 16:30:13 - INFO: Mini batch Iter: 0 train_loss= 10.14220 graph_loss= 10.02114 reg_loss= 0.12106
05/21/2022 16:30:16 - INFO: Mini batch Iter: 1 train_loss= 10.63814 graph_loss= 10.51690 reg_loss= 0.12124
05/21/2022 16:30:19 - INFO: Mini batch Iter: 2 train_loss= 10.40259 graph_loss= 10.28118 reg_loss= 0.12141
05/21/2022 16:30:21 - INFO: Mini batch Iter: 3 train_loss= 10.41062 graph_loss= 10.28905 reg_loss= 0.12157
05/21/2022 16:30:24 - INFO: Mini batch Iter: 4 train_loss= 10.70142 graph_loss= 10.57969 reg_loss= 0.12173
05/21/2022 16:30:26 - INFO: Mini batch Iter: 5 train_loss= 10.33138 graph_loss= 10.20953 reg_loss= 0.12185
05/21/2022 16:30:29 - INFO: Mini batch Iter: 6 train_loss= 10.32198 graph_loss= 10.20002 reg_loss= 0.12196
05/21/2022 16:30:32 - INFO: Mini batch Iter: 7 train_loss= 10.10466 graph_loss= 9.98258 reg_loss= 0.12208
05/21/2022 16:30:34 - INFO: Mini batch Iter: 8 train_loss= 10.40434 graph_loss= 10.28208 reg_loss= 0.12226
05/21/2022 16:30:37 - INFO: Mini batch Iter: 9 train_loss= 9.99896 graph_loss= 9.87653 reg_loss= 0.12243
05/21/2022 16:30:40 - INFO: Mini batch Iter: 10 train_loss= 10.41584 graph_loss= 10.29317 reg_loss= 0.12267
05/21/2022 16:30:42 - INFO: Mini batch Iter: 11 train_loss= 10.62502 graph_loss= 10.50213 reg_loss= 0.12289
05/21/2022 16:30:45 - INFO: Mini batch Iter: 12 train_loss= 10.18903 graph_loss= 10.06595 reg_loss= 0.12308
05/21/2022 16:30:49 - INFO: Mini batch Iter: 13 train_loss= 10.30355 graph_loss= 10.18023 reg_loss= 0.12332
05/21/2022 16:30:52 - INFO: Mini batch Iter: 14 train_loss= 10.39536 graph_loss= 10.27188 reg_loss= 0.12348
05/21/2022 16:30:55 - INFO: Mini batch Iter: 15 train_loss= 10.28246 graph_loss= 10.15882 reg_loss= 0.12364
05/21/2022 16:30:58 - INFO: Mini batch Iter: 16 train_loss= 10.60926 graph_loss= 10.48546 reg_loss= 0.12381
05/21/2022 16:31:01 - INFO: Mini batch Iter: 17 train_loss= 9.97207 graph_loss= 9.84811 reg_loss= 0.12396
05/21/2022 16:31:03 - INFO: Mini batch Iter: 18 train_loss= 10.36561 graph_loss= 10.24144 reg_loss= 0.12417
05/21/2022 16:31:07 - INFO: Mini batch Iter: 19 train_loss= 10.75238 graph_loss= 10.62801 reg_loss= 0.12437
05/21/2022 16:31:10 - INFO: Mini batch Iter: 20 train_loss= 10.14063 graph_loss= 10.01608 reg_loss= 0.12454
05/21/2022 16:31:13 - INFO: Mini batch Iter: 21 train_loss= 10.37148 graph_loss= 10.24673 reg_loss= 0.12475
05/21/2022 16:31:15 - INFO: Mini batch Iter: 22 train_loss= 10.54803 graph_loss= 10.42311 reg_loss= 0.12492
05/21/2022 16:31:18 - INFO: Mini batch Iter: 23 train_loss= 10.15056 graph_loss= 10.02548 reg_loss= 0.12509
05/21/2022 16:31:21 - INFO: Mini batch Iter: 24 train_loss= 10.93672 graph_loss= 10.81146 reg_loss= 0.12526
05/21/2022 16:31:23 - INFO: Mini batch Iter: 25 train_loss= 10.57199 graph_loss= 10.44658 reg_loss= 0.12541
05/21/2022 16:31:26 - INFO: Mini batch Iter: 26 train_loss= 10.21628 graph_loss= 10.09076 reg_loss= 0.12552
05/21/2022 16:31:28 - INFO: Mini batch Iter: 27 train_loss= 10.16349 graph_loss= 10.03788 reg_loss= 0.12561
05/21/2022 16:31:31 - INFO: Mini batch Iter: 28 train_loss= 10.85648 graph_loss= 10.73076 reg_loss= 0.12572
05/21/2022 16:31:34 - INFO: Mini batch Iter: 29 train_loss= 10.22699 graph_loss= 10.10119 reg_loss= 0.12580
05/21/2022 16:31:37 - INFO: Mini batch Iter: 30 train_loss= 10.22786 graph_loss= 10.10198 reg_loss= 0.12589
05/21/2022 16:31:40 - INFO: Mini batch Iter: 31 train_loss= 10.07903 graph_loss= 9.95307 reg_loss= 0.12596
05/21/2022 16:31:42 - INFO: Mini batch Iter: 32 train_loss= 10.83583 graph_loss= 10.70974 reg_loss= 0.12609
05/21/2022 16:31:45 - INFO: Mini batch Iter: 33 train_loss= 10.67901 graph_loss= 10.55281 reg_loss= 0.12620
05/21/2022 16:31:47 - INFO: Mini batch Iter: 34 train_loss= 10.42777 graph_loss= 10.30147 reg_loss= 0.12630
05/21/2022 16:31:50 - INFO: Mini batch Iter: 35 train_loss= 10.46315 graph_loss= 10.33677 reg_loss= 0.12638
05/21/2022 16:31:52 - INFO: Mini batch Iter: 36 train_loss= 10.40626 graph_loss= 10.27981 reg_loss= 0.12645
05/21/2022 16:31:55 - INFO: Mini batch Iter: 37 train_loss= 10.17576 graph_loss= 10.04921 reg_loss= 0.12654
05/21/2022 16:31:58 - INFO: Mini batch Iter: 38 train_loss= 10.33711 graph_loss= 10.21044 reg_loss= 0.12667
05/21/2022 16:31:59 - INFO: Mini batch Iter: 39 train_loss= 10.28395 graph_loss= 10.15711 reg_loss= 0.12684
05/21/2022 16:31:59 - INFO: Time for epoch : 75.42564558982849
05/21/2022 16:39:47 - INFO: Test results at epoch 9: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E2488>, {'operator_hadamard': [0.9653671051599226, 0.9653671051599226]}) best is : operator_hadamard 0.9653671051599226
05/21/2022 16:39:50 - INFO: Mini batch Iter: 0 train_loss= 10.29344 graph_loss= 10.16644 reg_loss= 0.12699
05/21/2022 16:39:53 - INFO: Mini batch Iter: 1 train_loss= 10.50393 graph_loss= 10.37684 reg_loss= 0.12710
05/21/2022 16:39:56 - INFO: Mini batch Iter: 2 train_loss= 10.50951 graph_loss= 10.38229 reg_loss= 0.12722
05/21/2022 16:39:58 - INFO: Mini batch Iter: 3 train_loss= 10.31264 graph_loss= 10.18533 reg_loss= 0.12731
05/21/2022 16:40:01 - INFO: Mini batch Iter: 4 train_loss= 10.37805 graph_loss= 10.25065 reg_loss= 0.12740
05/21/2022 16:40:05 - INFO: Mini batch Iter: 5 train_loss= 10.63220 graph_loss= 10.50469 reg_loss= 0.12751
05/21/2022 16:40:08 - INFO: Mini batch Iter: 6 train_loss= 10.33941 graph_loss= 10.21177 reg_loss= 0.12763
05/21/2022 16:40:11 - INFO: Mini batch Iter: 7 train_loss= 10.19303 graph_loss= 10.06530 reg_loss= 0.12773
05/21/2022 16:40:14 - INFO: Mini batch Iter: 8 train_loss= 10.45506 graph_loss= 10.32720 reg_loss= 0.12786
05/21/2022 16:40:17 - INFO: Mini batch Iter: 9 train_loss= 10.53356 graph_loss= 10.40557 reg_loss= 0.12799
05/21/2022 16:40:20 - INFO: Mini batch Iter: 10 train_loss= 10.30152 graph_loss= 10.17341 reg_loss= 0.12811
05/21/2022 16:40:22 - INFO: Mini batch Iter: 11 train_loss= 10.31059 graph_loss= 10.18236 reg_loss= 0.12823
05/21/2022 16:40:25 - INFO: Mini batch Iter: 12 train_loss= 10.46866 graph_loss= 10.34029 reg_loss= 0.12837
05/21/2022 16:40:28 - INFO: Mini batch Iter: 13 train_loss= 10.58418 graph_loss= 10.45567 reg_loss= 0.12851
05/21/2022 16:40:31 - INFO: Mini batch Iter: 14 train_loss= 10.43596 graph_loss= 10.30732 reg_loss= 0.12864
05/21/2022 16:40:34 - INFO: Mini batch Iter: 15 train_loss= 10.16345 graph_loss= 10.03468 reg_loss= 0.12877
05/21/2022 16:40:37 - INFO: Mini batch Iter: 16 train_loss= 10.16351 graph_loss= 10.03462 reg_loss= 0.12889
05/21/2022 16:40:39 - INFO: Mini batch Iter: 17 train_loss= 10.54324 graph_loss= 10.41420 reg_loss= 0.12905
05/21/2022 16:40:42 - INFO: Mini batch Iter: 18 train_loss= 10.29127 graph_loss= 10.16210 reg_loss= 0.12917
05/21/2022 16:40:44 - INFO: Mini batch Iter: 19 train_loss= 10.64840 graph_loss= 10.51909 reg_loss= 0.12931
05/21/2022 16:40:47 - INFO: Mini batch Iter: 20 train_loss= 10.29707 graph_loss= 10.16761 reg_loss= 0.12946
05/21/2022 16:40:50 - INFO: Mini batch Iter: 21 train_loss= 10.16101 graph_loss= 10.03142 reg_loss= 0.12959
05/21/2022 16:40:53 - INFO: Mini batch Iter: 22 train_loss= 10.72558 graph_loss= 10.59581 reg_loss= 0.12977
05/21/2022 16:40:55 - INFO: Mini batch Iter: 23 train_loss= 10.41249 graph_loss= 10.28259 reg_loss= 0.12990
05/21/2022 16:40:58 - INFO: Mini batch Iter: 24 train_loss= 10.17057 graph_loss= 10.04054 reg_loss= 0.13003
05/21/2022 16:41:01 - INFO: Mini batch Iter: 25 train_loss= 10.50638 graph_loss= 10.37620 reg_loss= 0.13018
05/21/2022 16:41:03 - INFO: Mini batch Iter: 26 train_loss= 10.02144 graph_loss= 9.89112 reg_loss= 0.13032
05/21/2022 16:41:06 - INFO: Mini batch Iter: 27 train_loss= 10.73936 graph_loss= 10.60883 reg_loss= 0.13052
05/21/2022 16:41:08 - INFO: Mini batch Iter: 28 train_loss= 10.23529 graph_loss= 10.10458 reg_loss= 0.13071
05/21/2022 16:41:12 - INFO: Mini batch Iter: 29 train_loss= 10.23270 graph_loss= 10.10180 reg_loss= 0.13090
05/21/2022 16:41:14 - INFO: Mini batch Iter: 30 train_loss= 10.24605 graph_loss= 10.11491 reg_loss= 0.13114
05/21/2022 16:41:17 - INFO: Mini batch Iter: 31 train_loss= 10.54508 graph_loss= 10.41374 reg_loss= 0.13135
05/21/2022 16:41:19 - INFO: Mini batch Iter: 32 train_loss= 10.39426 graph_loss= 10.26273 reg_loss= 0.13153
05/21/2022 16:41:22 - INFO: Mini batch Iter: 33 train_loss= 10.49720 graph_loss= 10.36547 reg_loss= 0.13173
05/21/2022 16:41:24 - INFO: Mini batch Iter: 34 train_loss= 10.48837 graph_loss= 10.35645 reg_loss= 0.13191
05/21/2022 16:41:27 - INFO: Mini batch Iter: 35 train_loss= 10.58293 graph_loss= 10.45084 reg_loss= 0.13209
05/21/2022 16:41:29 - INFO: Mini batch Iter: 36 train_loss= 10.50570 graph_loss= 10.37343 reg_loss= 0.13227
05/21/2022 16:41:32 - INFO: Mini batch Iter: 37 train_loss= 10.54662 graph_loss= 10.41418 reg_loss= 0.13245
05/21/2022 16:41:35 - INFO: Mini batch Iter: 38 train_loss= 10.58059 graph_loss= 10.44799 reg_loss= 0.13261
05/21/2022 16:41:37 - INFO: Mini batch Iter: 39 train_loss= 10.80458 graph_loss= 10.67184 reg_loss= 0.13274
05/21/2022 16:41:37 - INFO: Time for epoch : 75.50681471824646
05/21/2022 16:49:14 - INFO: Test results at epoch 10: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E3510>, {'operator_hadamard': [0.9686015074558572, 0.9686015074558572]}) best is : operator_hadamard 0.9686015074558572
05/21/2022 16:49:18 - INFO: Mini batch Iter: 0 train_loss= 10.42292 graph_loss= 10.29008 reg_loss= 0.13284
05/21/2022 16:49:20 - INFO: Mini batch Iter: 1 train_loss= 10.23945 graph_loss= 10.10651 reg_loss= 0.13294
05/21/2022 16:49:23 - INFO: Mini batch Iter: 2 train_loss= 10.27801 graph_loss= 10.14493 reg_loss= 0.13308
05/21/2022 16:49:26 - INFO: Mini batch Iter: 3 train_loss= 10.22407 graph_loss= 10.09083 reg_loss= 0.13324
05/21/2022 16:49:28 - INFO: Mini batch Iter: 4 train_loss= 10.48122 graph_loss= 10.34781 reg_loss= 0.13341
05/21/2022 16:49:31 - INFO: Mini batch Iter: 5 train_loss= 10.21999 graph_loss= 10.08641 reg_loss= 0.13358
05/21/2022 16:49:34 - INFO: Mini batch Iter: 6 train_loss= 10.20672 graph_loss= 10.07296 reg_loss= 0.13376
05/21/2022 16:49:36 - INFO: Mini batch Iter: 7 train_loss= 10.31054 graph_loss= 10.17659 reg_loss= 0.13395
05/21/2022 16:49:39 - INFO: Mini batch Iter: 8 train_loss= 10.10378 graph_loss= 9.96962 reg_loss= 0.13416
05/21/2022 16:49:42 - INFO: Mini batch Iter: 9 train_loss= 10.43513 graph_loss= 10.30074 reg_loss= 0.13440
05/21/2022 16:49:44 - INFO: Mini batch Iter: 10 train_loss= 10.35683 graph_loss= 10.22221 reg_loss= 0.13462
05/21/2022 16:49:47 - INFO: Mini batch Iter: 11 train_loss= 10.73781 graph_loss= 10.60298 reg_loss= 0.13483
05/21/2022 16:49:50 - INFO: Mini batch Iter: 12 train_loss= 10.34914 graph_loss= 10.21414 reg_loss= 0.13500
05/21/2022 16:49:52 - INFO: Mini batch Iter: 13 train_loss= 10.28500 graph_loss= 10.14987 reg_loss= 0.13513
05/21/2022 16:49:55 - INFO: Mini batch Iter: 14 train_loss= 10.20060 graph_loss= 10.06536 reg_loss= 0.13524
05/21/2022 16:49:57 - INFO: Mini batch Iter: 15 train_loss= 10.54410 graph_loss= 10.40874 reg_loss= 0.13537
05/21/2022 16:50:00 - INFO: Mini batch Iter: 16 train_loss= 10.46180 graph_loss= 10.32630 reg_loss= 0.13550
05/21/2022 16:50:03 - INFO: Mini batch Iter: 17 train_loss= 10.18602 graph_loss= 10.05041 reg_loss= 0.13561
05/21/2022 16:50:05 - INFO: Mini batch Iter: 18 train_loss= 10.54890 graph_loss= 10.41316 reg_loss= 0.13574
05/21/2022 16:50:08 - INFO: Mini batch Iter: 19 train_loss= 10.42039 graph_loss= 10.28452 reg_loss= 0.13587
05/21/2022 16:50:11 - INFO: Mini batch Iter: 20 train_loss= 10.24846 graph_loss= 10.11248 reg_loss= 0.13598
05/21/2022 16:50:13 - INFO: Mini batch Iter: 21 train_loss= 10.46141 graph_loss= 10.32529 reg_loss= 0.13612
05/21/2022 16:50:17 - INFO: Mini batch Iter: 22 train_loss= 10.65548 graph_loss= 10.51924 reg_loss= 0.13624
05/21/2022 16:50:20 - INFO: Mini batch Iter: 23 train_loss= 10.04893 graph_loss= 9.91263 reg_loss= 0.13629
05/21/2022 16:50:23 - INFO: Mini batch Iter: 24 train_loss= 10.52683 graph_loss= 10.39044 reg_loss= 0.13639
05/21/2022 16:50:25 - INFO: Mini batch Iter: 25 train_loss= 10.27481 graph_loss= 10.13832 reg_loss= 0.13649
05/21/2022 16:50:29 - INFO: Mini batch Iter: 26 train_loss= 10.46697 graph_loss= 10.33039 reg_loss= 0.13658
05/21/2022 16:50:31 - INFO: Mini batch Iter: 27 train_loss= 10.35367 graph_loss= 10.21699 reg_loss= 0.13668
05/21/2022 16:50:35 - INFO: Mini batch Iter: 28 train_loss= 10.42430 graph_loss= 10.28753 reg_loss= 0.13677
05/21/2022 16:50:37 - INFO: Mini batch Iter: 29 train_loss= 10.32327 graph_loss= 10.18639 reg_loss= 0.13687
05/21/2022 16:50:40 - INFO: Mini batch Iter: 30 train_loss= 10.36285 graph_loss= 10.22585 reg_loss= 0.13700
05/21/2022 16:50:44 - INFO: Mini batch Iter: 31 train_loss= 10.63054 graph_loss= 10.49341 reg_loss= 0.13714
05/21/2022 16:50:47 - INFO: Mini batch Iter: 32 train_loss= 10.48422 graph_loss= 10.34698 reg_loss= 0.13723
05/21/2022 16:50:49 - INFO: Mini batch Iter: 33 train_loss= 10.33445 graph_loss= 10.19714 reg_loss= 0.13731
05/21/2022 16:50:52 - INFO: Mini batch Iter: 34 train_loss= 10.41449 graph_loss= 10.27706 reg_loss= 0.13742
05/21/2022 16:50:55 - INFO: Mini batch Iter: 35 train_loss= 10.15612 graph_loss= 10.01857 reg_loss= 0.13755
05/21/2022 16:50:57 - INFO: Mini batch Iter: 36 train_loss= 10.17827 graph_loss= 10.04057 reg_loss= 0.13770
05/21/2022 16:51:00 - INFO: Mini batch Iter: 37 train_loss= 10.11750 graph_loss= 9.97963 reg_loss= 0.13787
05/21/2022 16:51:03 - INFO: Mini batch Iter: 38 train_loss= 10.14836 graph_loss= 10.01029 reg_loss= 0.13807
05/21/2022 16:51:05 - INFO: Mini batch Iter: 39 train_loss= 10.42254 graph_loss= 10.28426 reg_loss= 0.13827
05/21/2022 16:51:05 - INFO: Time for epoch : 75.95461964607239
05/21/2022 16:58:10 - INFO: Test results at epoch 11: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B568A0ED08>, {'operator_hadamard': [0.9730134459687019, 0.9730134459687019]}) best is : operator_hadamard 0.9730134459687019
05/21/2022 16:58:12 - INFO: Mini batch Iter: 0 train_loss= 11.10394 graph_loss= 10.96549 reg_loss= 0.13845
05/21/2022 16:58:15 - INFO: Mini batch Iter: 1 train_loss= 10.51119 graph_loss= 10.37256 reg_loss= 0.13863
05/21/2022 16:58:19 - INFO: Mini batch Iter: 2 train_loss= 10.54979 graph_loss= 10.41097 reg_loss= 0.13881
05/21/2022 16:58:21 - INFO: Mini batch Iter: 3 train_loss= 10.45385 graph_loss= 10.31487 reg_loss= 0.13898
05/21/2022 16:58:24 - INFO: Mini batch Iter: 4 train_loss= 10.33508 graph_loss= 10.19595 reg_loss= 0.13913
05/21/2022 16:58:27 - INFO: Mini batch Iter: 5 train_loss= 10.34263 graph_loss= 10.20335 reg_loss= 0.13928
05/21/2022 16:58:30 - INFO: Mini batch Iter: 6 train_loss= 10.65505 graph_loss= 10.51560 reg_loss= 0.13944
05/21/2022 16:58:32 - INFO: Mini batch Iter: 7 train_loss= 10.38120 graph_loss= 10.24160 reg_loss= 0.13959
05/21/2022 16:58:35 - INFO: Mini batch Iter: 8 train_loss= 10.45462 graph_loss= 10.31486 reg_loss= 0.13977
05/21/2022 16:58:37 - INFO: Mini batch Iter: 9 train_loss= 10.15555 graph_loss= 10.01563 reg_loss= 0.13992
05/21/2022 16:58:40 - INFO: Mini batch Iter: 10 train_loss= 10.07537 graph_loss= 9.93529 reg_loss= 0.14008
05/21/2022 16:58:43 - INFO: Mini batch Iter: 11 train_loss= 10.55337 graph_loss= 10.41307 reg_loss= 0.14030
05/21/2022 16:58:46 - INFO: Mini batch Iter: 12 train_loss= 10.58678 graph_loss= 10.44629 reg_loss= 0.14050
05/21/2022 16:58:49 - INFO: Mini batch Iter: 13 train_loss= 10.23464 graph_loss= 10.09396 reg_loss= 0.14068
05/21/2022 16:58:51 - INFO: Mini batch Iter: 14 train_loss= 10.25030 graph_loss= 10.10942 reg_loss= 0.14089
05/21/2022 16:58:54 - INFO: Mini batch Iter: 15 train_loss= 10.13920 graph_loss= 9.99811 reg_loss= 0.14109
05/21/2022 16:58:57 - INFO: Mini batch Iter: 16 train_loss= 10.99692 graph_loss= 10.85557 reg_loss= 0.14135
05/21/2022 16:59:00 - INFO: Mini batch Iter: 17 train_loss= 10.24507 graph_loss= 10.10348 reg_loss= 0.14159
05/21/2022 16:59:03 - INFO: Mini batch Iter: 18 train_loss= 10.38873 graph_loss= 10.24692 reg_loss= 0.14182
05/21/2022 16:59:05 - INFO: Mini batch Iter: 19 train_loss= 10.29278 graph_loss= 10.15074 reg_loss= 0.14205
05/21/2022 16:59:08 - INFO: Mini batch Iter: 20 train_loss= 10.42184 graph_loss= 10.27955 reg_loss= 0.14230
05/21/2022 16:59:11 - INFO: Mini batch Iter: 21 train_loss= 10.58338 graph_loss= 10.44086 reg_loss= 0.14252
05/21/2022 16:59:14 - INFO: Mini batch Iter: 22 train_loss= 10.28117 graph_loss= 10.13848 reg_loss= 0.14269
05/21/2022 16:59:17 - INFO: Mini batch Iter: 23 train_loss= 10.24758 graph_loss= 10.10471 reg_loss= 0.14286
05/21/2022 16:59:19 - INFO: Mini batch Iter: 24 train_loss= 10.43126 graph_loss= 10.28822 reg_loss= 0.14305
05/21/2022 16:59:22 - INFO: Mini batch Iter: 25 train_loss= 10.20269 graph_loss= 10.05946 reg_loss= 0.14323
05/21/2022 16:59:24 - INFO: Mini batch Iter: 26 train_loss= 10.23095 graph_loss= 10.08753 reg_loss= 0.14342
05/21/2022 16:59:27 - INFO: Mini batch Iter: 27 train_loss= 10.21946 graph_loss= 10.07582 reg_loss= 0.14365
05/21/2022 16:59:30 - INFO: Mini batch Iter: 28 train_loss= 10.33877 graph_loss= 10.19493 reg_loss= 0.14385
05/21/2022 16:59:32 - INFO: Mini batch Iter: 29 train_loss= 10.27247 graph_loss= 10.12844 reg_loss= 0.14403
05/21/2022 16:59:35 - INFO: Mini batch Iter: 30 train_loss= 10.21521 graph_loss= 10.07100 reg_loss= 0.14421
05/21/2022 16:59:39 - INFO: Mini batch Iter: 31 train_loss= 10.02503 graph_loss= 9.88060 reg_loss= 0.14444
05/21/2022 16:59:42 - INFO: Mini batch Iter: 32 train_loss= 10.26562 graph_loss= 10.12089 reg_loss= 0.14472
05/21/2022 16:59:45 - INFO: Mini batch Iter: 33 train_loss= 10.45825 graph_loss= 10.31321 reg_loss= 0.14503
05/21/2022 16:59:47 - INFO: Mini batch Iter: 34 train_loss= 10.05123 graph_loss= 9.90596 reg_loss= 0.14527
05/21/2022 16:59:50 - INFO: Mini batch Iter: 35 train_loss= 10.44012 graph_loss= 10.29461 reg_loss= 0.14551
05/21/2022 16:59:52 - INFO: Mini batch Iter: 36 train_loss= 10.03809 graph_loss= 9.89236 reg_loss= 0.14573
05/21/2022 16:59:55 - INFO: Mini batch Iter: 37 train_loss= 10.51677 graph_loss= 10.37080 reg_loss= 0.14597
05/21/2022 16:59:58 - INFO: Mini batch Iter: 38 train_loss= 10.19315 graph_loss= 10.04699 reg_loss= 0.14616
05/21/2022 16:59:59 - INFO: Mini batch Iter: 39 train_loss= 9.98293 graph_loss= 9.83660 reg_loss= 0.14633
05/21/2022 17:00:00 - INFO: Time for epoch : 75.32322096824646
05/21/2022 17:07:30 - INFO: Test results at epoch 12: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B5689E2EA0>, {'operator_hadamard': [0.9703599624326236, 0.9703599624326236]}) best is : operator_hadamard 0.9703599624326236
05/21/2022 17:07:33 - INFO: Mini batch Iter: 0 train_loss= 10.18601 graph_loss= 10.03950 reg_loss= 0.14651
05/21/2022 17:07:35 - INFO: Mini batch Iter: 1 train_loss= 10.01091 graph_loss= 9.86423 reg_loss= 0.14668
05/21/2022 17:07:38 - INFO: Mini batch Iter: 2 train_loss= 10.23652 graph_loss= 10.08962 reg_loss= 0.14690
05/21/2022 17:07:40 - INFO: Mini batch Iter: 3 train_loss= 10.62809 graph_loss= 10.48100 reg_loss= 0.14709
05/21/2022 17:07:43 - INFO: Mini batch Iter: 4 train_loss= 10.07991 graph_loss= 9.93264 reg_loss= 0.14727
05/21/2022 17:07:45 - INFO: Mini batch Iter: 5 train_loss= 10.07219 graph_loss= 9.92474 reg_loss= 0.14744
05/21/2022 17:07:48 - INFO: Mini batch Iter: 6 train_loss= 10.18351 graph_loss= 10.03588 reg_loss= 0.14763
05/21/2022 17:07:51 - INFO: Mini batch Iter: 7 train_loss= 9.97702 graph_loss= 9.82919 reg_loss= 0.14783
05/21/2022 17:07:53 - INFO: Mini batch Iter: 8 train_loss= 10.14604 graph_loss= 9.99799 reg_loss= 0.14805
05/21/2022 17:07:57 - INFO: Mini batch Iter: 9 train_loss= 10.76700 graph_loss= 10.61876 reg_loss= 0.14824
05/21/2022 17:07:59 - INFO: Mini batch Iter: 10 train_loss= 9.96462 graph_loss= 9.81622 reg_loss= 0.14840
05/21/2022 17:08:02 - INFO: Mini batch Iter: 11 train_loss= 10.17446 graph_loss= 10.02588 reg_loss= 0.14858
05/21/2022 17:08:05 - INFO: Mini batch Iter: 12 train_loss= 10.32393 graph_loss= 10.17518 reg_loss= 0.14875
05/21/2022 17:08:07 - INFO: Mini batch Iter: 13 train_loss= 10.43961 graph_loss= 10.29073 reg_loss= 0.14888
05/21/2022 17:08:10 - INFO: Mini batch Iter: 14 train_loss= 10.53780 graph_loss= 10.38878 reg_loss= 0.14902
05/21/2022 17:08:13 - INFO: Mini batch Iter: 15 train_loss= 10.36907 graph_loss= 10.21991 reg_loss= 0.14916
05/21/2022 17:08:16 - INFO: Mini batch Iter: 16 train_loss= 10.43245 graph_loss= 10.28319 reg_loss= 0.14926
05/21/2022 17:08:19 - INFO: Mini batch Iter: 17 train_loss= 10.65920 graph_loss= 10.50985 reg_loss= 0.14935
05/21/2022 17:08:21 - INFO: Mini batch Iter: 18 train_loss= 9.93547 graph_loss= 9.78603 reg_loss= 0.14944
05/21/2022 17:08:25 - INFO: Mini batch Iter: 19 train_loss= 10.50068 graph_loss= 10.35117 reg_loss= 0.14951
05/21/2022 17:08:27 - INFO: Mini batch Iter: 20 train_loss= 10.30400 graph_loss= 10.15445 reg_loss= 0.14955
05/21/2022 17:08:30 - INFO: Mini batch Iter: 21 train_loss= 10.39078 graph_loss= 10.24119 reg_loss= 0.14958
05/21/2022 17:08:32 - INFO: Mini batch Iter: 22 train_loss= 10.65051 graph_loss= 10.50091 reg_loss= 0.14960
05/21/2022 17:08:35 - INFO: Mini batch Iter: 23 train_loss= 9.91599 graph_loss= 9.76637 reg_loss= 0.14963
05/21/2022 17:08:38 - INFO: Mini batch Iter: 24 train_loss= 10.11677 graph_loss= 9.96705 reg_loss= 0.14972
05/21/2022 17:08:41 - INFO: Mini batch Iter: 25 train_loss= 10.15982 graph_loss= 10.01001 reg_loss= 0.14981
05/21/2022 17:08:43 - INFO: Mini batch Iter: 26 train_loss= 9.91071 graph_loss= 9.76078 reg_loss= 0.14993
05/21/2022 17:08:45 - INFO: Mini batch Iter: 27 train_loss= 10.24210 graph_loss= 10.09198 reg_loss= 0.15012
05/21/2022 17:08:48 - INFO: Mini batch Iter: 28 train_loss= 10.15390 graph_loss= 10.00359 reg_loss= 0.15031
05/21/2022 17:08:51 - INFO: Mini batch Iter: 29 train_loss= 10.23331 graph_loss= 10.08287 reg_loss= 0.15044
05/21/2022 17:08:54 - INFO: Mini batch Iter: 30 train_loss= 10.41887 graph_loss= 10.26828 reg_loss= 0.15059
05/21/2022 17:08:59 - INFO: Mini batch Iter: 31 train_loss= 10.44670 graph_loss= 10.29599 reg_loss= 0.15070
05/21/2022 17:09:02 - INFO: Mini batch Iter: 32 train_loss= 10.35657 graph_loss= 10.20575 reg_loss= 0.15082
05/21/2022 17:09:04 - INFO: Mini batch Iter: 33 train_loss= 10.13912 graph_loss= 9.98819 reg_loss= 0.15093
05/21/2022 17:09:07 - INFO: Mini batch Iter: 34 train_loss= 10.54398 graph_loss= 10.39290 reg_loss= 0.15109
05/21/2022 17:09:10 - INFO: Mini batch Iter: 35 train_loss= 10.29973 graph_loss= 10.14855 reg_loss= 0.15118
05/21/2022 17:09:14 - INFO: Mini batch Iter: 36 train_loss= 10.91847 graph_loss= 10.76721 reg_loss= 0.15126
05/21/2022 17:09:17 - INFO: Mini batch Iter: 37 train_loss= 10.30603 graph_loss= 10.15471 reg_loss= 0.15132
05/21/2022 17:09:21 - INFO: Mini batch Iter: 38 train_loss= 10.99336 graph_loss= 10.84200 reg_loss= 0.15137
05/21/2022 17:09:23 - INFO: Mini batch Iter: 39 train_loss= 9.97705 graph_loss= 9.82562 reg_loss= 0.15142
05/21/2022 17:09:23 - INFO: Time for epoch : 75.62507629394531
05/21/2022 17:17:03 - INFO: Test results at epoch 13: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B561A056A8>, {'operator_hadamard': [0.9675878617016123, 0.9675878617016123]}) best is : operator_hadamard 0.9675878617016123
05/21/2022 17:17:05 - INFO: Mini batch Iter: 0 train_loss= 10.18345 graph_loss= 10.03194 reg_loss= 0.15151
05/21/2022 17:17:08 - INFO: Mini batch Iter: 1 train_loss= 10.69492 graph_loss= 10.54330 reg_loss= 0.15162
05/21/2022 17:17:11 - INFO: Mini batch Iter: 2 train_loss= 10.24938 graph_loss= 10.09769 reg_loss= 0.15169
05/21/2022 17:17:13 - INFO: Mini batch Iter: 3 train_loss= 10.32814 graph_loss= 10.17636 reg_loss= 0.15178
05/21/2022 17:17:16 - INFO: Mini batch Iter: 4 train_loss= 10.12720 graph_loss= 9.97531 reg_loss= 0.15189
05/21/2022 17:17:18 - INFO: Mini batch Iter: 5 train_loss= 10.18458 graph_loss= 10.03255 reg_loss= 0.15203
05/21/2022 17:17:21 - INFO: Mini batch Iter: 6 train_loss= 10.46019 graph_loss= 10.30803 reg_loss= 0.15216
05/21/2022 17:17:24 - INFO: Mini batch Iter: 7 train_loss= 10.27758 graph_loss= 10.12528 reg_loss= 0.15230
05/21/2022 17:17:27 - INFO: Mini batch Iter: 8 train_loss= 10.38579 graph_loss= 10.23332 reg_loss= 0.15247
05/21/2022 17:17:30 - INFO: Mini batch Iter: 9 train_loss= 10.34938 graph_loss= 10.19675 reg_loss= 0.15263
05/21/2022 17:17:32 - INFO: Mini batch Iter: 10 train_loss= 10.33569 graph_loss= 10.18292 reg_loss= 0.15278
05/21/2022 17:17:35 - INFO: Mini batch Iter: 11 train_loss= 10.32561 graph_loss= 10.17268 reg_loss= 0.15293
05/21/2022 17:17:37 - INFO: Mini batch Iter: 12 train_loss= 10.10720 graph_loss= 9.95412 reg_loss= 0.15308
05/21/2022 17:17:40 - INFO: Mini batch Iter: 13 train_loss= 10.46420 graph_loss= 10.31094 reg_loss= 0.15326
05/21/2022 17:17:43 - INFO: Mini batch Iter: 14 train_loss= 10.06396 graph_loss= 9.91059 reg_loss= 0.15338
05/21/2022 17:17:45 - INFO: Mini batch Iter: 15 train_loss= 10.13321 graph_loss= 9.97969 reg_loss= 0.15351
05/21/2022 17:17:48 - INFO: Mini batch Iter: 16 train_loss= 10.32516 graph_loss= 10.17150 reg_loss= 0.15366
05/21/2022 17:17:51 - INFO: Mini batch Iter: 17 train_loss= 10.02035 graph_loss= 9.86655 reg_loss= 0.15380
05/21/2022 17:17:55 - INFO: Mini batch Iter: 18 train_loss= 10.90269 graph_loss= 10.74871 reg_loss= 0.15398
05/21/2022 17:17:57 - INFO: Mini batch Iter: 19 train_loss= 10.18544 graph_loss= 10.03134 reg_loss= 0.15411
05/21/2022 17:18:01 - INFO: Mini batch Iter: 20 train_loss= 10.24207 graph_loss= 10.08783 reg_loss= 0.15425
05/21/2022 17:18:03 - INFO: Mini batch Iter: 21 train_loss= 10.31423 graph_loss= 10.15988 reg_loss= 0.15434
05/21/2022 17:18:06 - INFO: Mini batch Iter: 22 train_loss= 10.54067 graph_loss= 10.38623 reg_loss= 0.15444
05/21/2022 17:18:08 - INFO: Mini batch Iter: 23 train_loss= 10.31914 graph_loss= 10.16462 reg_loss= 0.15452
05/21/2022 17:18:12 - INFO: Mini batch Iter: 24 train_loss= 10.25308 graph_loss= 10.09847 reg_loss= 0.15461
05/21/2022 17:18:15 - INFO: Mini batch Iter: 25 train_loss= 10.50480 graph_loss= 10.35008 reg_loss= 0.15472
05/21/2022 17:18:17 - INFO: Mini batch Iter: 26 train_loss= 9.96663 graph_loss= 9.81180 reg_loss= 0.15483
05/21/2022 17:18:20 - INFO: Mini batch Iter: 27 train_loss= 10.15025 graph_loss= 9.99527 reg_loss= 0.15498
05/21/2022 17:18:23 - INFO: Mini batch Iter: 28 train_loss= 10.05493 graph_loss= 9.89980 reg_loss= 0.15513
05/21/2022 17:18:26 - INFO: Mini batch Iter: 29 train_loss= 10.06598 graph_loss= 9.91068 reg_loss= 0.15529
05/21/2022 17:18:29 - INFO: Mini batch Iter: 30 train_loss= 10.51122 graph_loss= 10.35572 reg_loss= 0.15550
05/21/2022 17:18:32 - INFO: Mini batch Iter: 31 train_loss= 10.37344 graph_loss= 10.21776 reg_loss= 0.15568
05/21/2022 17:18:34 - INFO: Mini batch Iter: 32 train_loss= 10.13894 graph_loss= 9.98309 reg_loss= 0.15585
05/21/2022 17:18:37 - INFO: Mini batch Iter: 33 train_loss= 10.43188 graph_loss= 10.27583 reg_loss= 0.15605
05/21/2022 17:18:40 - INFO: Mini batch Iter: 34 train_loss= 10.13976 graph_loss= 9.98351 reg_loss= 0.15625
05/21/2022 17:18:42 - INFO: Mini batch Iter: 35 train_loss= 9.93338 graph_loss= 9.77693 reg_loss= 0.15645
05/21/2022 17:18:45 - INFO: Mini batch Iter: 36 train_loss= 10.15991 graph_loss= 10.00320 reg_loss= 0.15671
05/21/2022 17:18:47 - INFO: Mini batch Iter: 37 train_loss= 10.12224 graph_loss= 9.96528 reg_loss= 0.15696
05/21/2022 17:18:51 - INFO: Mini batch Iter: 38 train_loss= 10.37896 graph_loss= 10.22174 reg_loss= 0.15721
05/21/2022 17:18:53 - INFO: Mini batch Iter: 39 train_loss= 10.31793 graph_loss= 10.16051 reg_loss= 0.15741
05/21/2022 17:18:53 - INFO: Time for epoch : 75.61300349235535
05/21/2022 17:26:43 - INFO: Test results at epoch 14: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x000002B561A05C80>, {'operator_hadamard': [0.9702968613630016, 0.9702968613630016]}) best is : operator_hadamard 0.9702968613630016
05/21/2022 17:26:46 - INFO: Mini batch Iter: 0 train_loss= 10.24901 graph_loss= 10.09138 reg_loss= 0.15762
05/21/2022 17:26:48 - INFO: Mini batch Iter: 1 train_loss= 10.13271 graph_loss= 9.97489 reg_loss= 0.15782
05/21/2022 17:26:51 - INFO: Mini batch Iter: 2 train_loss= 10.52020 graph_loss= 10.36219 reg_loss= 0.15801
05/21/2022 17:26:54 - INFO: Mini batch Iter: 3 train_loss= 10.15681 graph_loss= 9.99863 reg_loss= 0.15818
05/21/2022 17:26:56 - INFO: Mini batch Iter: 4 train_loss= 10.22704 graph_loss= 10.06867 reg_loss= 0.15837
05/21/2022 17:26:59 - INFO: Mini batch Iter: 5 train_loss= 10.52195 graph_loss= 10.36339 reg_loss= 0.15856
05/21/2022 17:27:01 - INFO: Mini batch Iter: 6 train_loss= 10.18133 graph_loss= 10.02260 reg_loss= 0.15874
05/21/2022 17:27:04 - INFO: Mini batch Iter: 7 train_loss= 10.18373 graph_loss= 10.02481 reg_loss= 0.15892
05/21/2022 17:27:07 - INFO: Mini batch Iter: 8 train_loss= 10.22062 graph_loss= 10.06153 reg_loss= 0.15910
05/21/2022 17:27:09 - INFO: Mini batch Iter: 9 train_loss= 9.94507 graph_loss= 9.78580 reg_loss= 0.15928
05/21/2022 17:27:12 - INFO: Mini batch Iter: 10 train_loss= 10.40602 graph_loss= 10.24653 reg_loss= 0.15949
05/21/2022 17:27:15 - INFO: Mini batch Iter: 11 train_loss= 10.17143 graph_loss= 10.01174 reg_loss= 0.15970
05/21/2022 17:27:18 - INFO: Mini batch Iter: 12 train_loss= 10.55005 graph_loss= 10.39016 reg_loss= 0.15989
05/21/2022 17:27:20 - INFO: Mini batch Iter: 13 train_loss= 10.09677 graph_loss= 9.93677 reg_loss= 0.16000
05/21/2022 17:27:23 - INFO: Mini batch Iter: 14 train_loss= 10.07676 graph_loss= 9.91665 reg_loss= 0.16010
05/21/2022 17:27:26 - INFO: Mini batch Iter: 15 train_loss= 10.54040 graph_loss= 10.38017 reg_loss= 0.16023
05/21/2022 17:27:29 - INFO: Mini batch Iter: 16 train_loss= 10.05494 graph_loss= 9.89459 reg_loss= 0.16035
05/21/2022 17:27:31 - INFO: Mini batch Iter: 17 train_loss= 10.13637 graph_loss= 9.97593 reg_loss= 0.16044
05/21/2022 17:27:35 - INFO: Mini batch Iter: 18 train_loss= 10.55756 graph_loss= 10.39706 reg_loss= 0.16050
05/21/2022 17:27:37 - INFO: Mini batch Iter: 19 train_loss= 10.47549 graph_loss= 10.31492 reg_loss= 0.16058
05/21/2022 17:27:41 - INFO: Mini batch Iter: 20 train_loss= 10.00251 graph_loss= 9.84186 reg_loss= 0.16065
05/21/2022 17:27:44 - INFO: Mini batch Iter: 21 train_loss= 10.33991 graph_loss= 10.17920 reg_loss= 0.16071
05/21/2022 17:27:47 - INFO: Mini batch Iter: 22 train_loss= 10.04599 graph_loss= 9.88520 reg_loss= 0.16079
05/21/2022 17:27:49 - INFO: Mini batch Iter: 23 train_loss= 10.08548 graph_loss= 9.92457 reg_loss= 0.16091
05/21/2022 17:27:52 - INFO: Mini batch Iter: 24 train_loss= 10.00351 graph_loss= 9.84243 reg_loss= 0.16108
05/21/2022 17:27:54 - INFO: Mini batch Iter: 25 train_loss= 9.96600 graph_loss= 9.80470 reg_loss= 0.16129
05/21/2022 17:27:57 - INFO: Mini batch Iter: 26 train_loss= 10.20005 graph_loss= 10.03853 reg_loss= 0.16153
05/21/2022 17:28:00 - INFO: Mini batch Iter: 27 train_loss= 10.28746 graph_loss= 10.12571 reg_loss= 0.16175
05/21/2022 17:28:03 - INFO: Mini batch Iter: 28 train_loss= 10.15203 graph_loss= 9.99009 reg_loss= 0.16194
05/21/2022 17:28:06 - INFO: Mini batch Iter: 29 train_loss= 10.79317 graph_loss= 10.63103 reg_loss= 0.16213
05/21/2022 17:28:09 - INFO: Mini batch Iter: 30 train_loss= 9.92379 graph_loss= 9.76150 reg_loss= 0.16229
05/21/2022 17:28:11 - INFO: Mini batch Iter: 31 train_loss= 10.13660 graph_loss= 9.97411 reg_loss= 0.16249
05/21/2022 17:28:14 - INFO: Mini batch Iter: 32 train_loss= 10.03164 graph_loss= 9.86894 reg_loss= 0.16270
05/21/2022 17:28:17 - INFO: Mini batch Iter: 33 train_loss= 10.32545 graph_loss= 10.16249 reg_loss= 0.16296
05/21/2022 17:28:19 - INFO: Mini batch Iter: 34 train_loss= 9.86033 graph_loss= 9.69713 reg_loss= 0.16319
05/21/2022 17:28:22 - INFO: Mini batch Iter: 35 train_loss= 10.26765 graph_loss= 10.10419 reg_loss= 0.16346
05/21/2022 17:28:26 - INFO: Mini batch Iter: 36 train_loss= 10.54166 graph_loss= 10.37794 reg_loss= 0.16372
05/21/2022 17:28:28 - INFO: Mini batch Iter: 37 train_loss= 10.46240 graph_loss= 10.29846 reg_loss= 0.16394
05/21/2022 17:28:31 - INFO: Mini batch Iter: 38 train_loss= 10.23323 graph_loss= 10.06909 reg_loss= 0.16414
05/21/2022 17:28:33 - INFO: Mini batch Iter: 39 train_loss= 10.06036 graph_loss= 9.89605 reg_loss= 0.16431
05/21/2022 17:28:33 - INFO: Time for epoch : 75.9132010936737
05/21/2022 21:52:44 - INFO: dict_items([('base_model', 'DyMADC'), ('model', 'default'), ('test_subset', 0.25), ('min_time', 1), ('max_time', 9), ('dataset', 'reddit'), ('dataname', 'reddit_8_by_edgesNumber_0.25'), ('time_steps', 9), ('GPU_ID', 0), ('epochs', 30), ('batch_size', 256), ('featureless', 'True'), ('max_gradient_norm', 1.0), ('test_freq', 1), ('val_freq', 1), ('neg_sample_size', 10), ('walk_len', 40), ('neg_weight', 1.0), ('learning_rate', 0.001), ('spatial_drop', 0.1), ('temporal_drop', 0.5), ('weight_decay', 0.0005), ('use_residual', 'False'), ('structural_head_config', '16,8,8'), ('structural_layer_config', '128'), ('temporal_head_config', '16'), ('temporal_layer_config', '128'), ('position_ffn', 'True'), ('optimizer', 'adam'), ('seed', 7), ('save_dir', '/output'), ('log_dir', '/log'), ('csv_dir', '/csv'), ('model_dir', '/model'), ('window', -1)])
05/21/2022 21:54:16 - INFO: # train: 504335, # test: 168112
05/21/2022 21:54:44 - WARNING: From D:\Anaconda3\envs\tf_1\lib\site-packages\tensorflow\python\ops\sparse_grad.py:281: calling sparse_reduce_sum (from tensorflow.python.ops.sparse_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
05/21/2022 21:55:17 - INFO: Mini batch Iter: 0 train_loss= 11.16347 graph_loss= 11.08558 reg_loss= 0.07789
05/21/2022 21:55:21 - INFO: Mini batch Iter: 1 train_loss= 11.15204 graph_loss= 11.07758 reg_loss= 0.07446
05/21/2022 21:55:24 - INFO: Mini batch Iter: 2 train_loss= 11.15386 graph_loss= 11.08220 reg_loss= 0.07167
05/21/2022 21:55:26 - INFO: Mini batch Iter: 3 train_loss= 11.11972 graph_loss= 11.05048 reg_loss= 0.06924
05/21/2022 21:55:29 - INFO: Mini batch Iter: 4 train_loss= 11.11314 graph_loss= 11.04614 reg_loss= 0.06700
05/21/2022 21:55:33 - INFO: Mini batch Iter: 5 train_loss= 11.14009 graph_loss= 11.07493 reg_loss= 0.06516
05/21/2022 21:55:36 - INFO: Mini batch Iter: 6 train_loss= 11.09375 graph_loss= 11.03002 reg_loss= 0.06373
05/21/2022 21:55:38 - INFO: Mini batch Iter: 7 train_loss= 11.07171 graph_loss= 11.00920 reg_loss= 0.06252
05/21/2022 21:55:41 - INFO: Mini batch Iter: 8 train_loss= 11.02169 graph_loss= 10.96023 reg_loss= 0.06146
05/21/2022 21:55:43 - INFO: Mini batch Iter: 9 train_loss= 10.98199 graph_loss= 10.92144 reg_loss= 0.06055
05/21/2022 21:55:45 - INFO: Mini batch Iter: 10 train_loss= 11.03245 graph_loss= 10.97266 reg_loss= 0.05979
05/21/2022 21:55:48 - INFO: Mini batch Iter: 11 train_loss= 10.96973 graph_loss= 10.91056 reg_loss= 0.05917
05/21/2022 21:55:51 - INFO: Mini batch Iter: 12 train_loss= 10.94343 graph_loss= 10.88474 reg_loss= 0.05869
05/21/2022 21:55:54 - INFO: Mini batch Iter: 13 train_loss= 10.99762 graph_loss= 10.93924 reg_loss= 0.05838
05/21/2022 21:55:56 - INFO: Mini batch Iter: 14 train_loss= 10.92508 graph_loss= 10.86693 reg_loss= 0.05816
05/21/2022 21:55:59 - INFO: Mini batch Iter: 15 train_loss= 10.87073 graph_loss= 10.81270 reg_loss= 0.05804
05/21/2022 21:56:02 - INFO: Mini batch Iter: 16 train_loss= 10.89269 graph_loss= 10.83470 reg_loss= 0.05799
05/21/2022 21:56:05 - INFO: Mini batch Iter: 17 train_loss= 10.91393 graph_loss= 10.85589 reg_loss= 0.05803
05/21/2022 21:56:07 - INFO: Mini batch Iter: 18 train_loss= 10.90155 graph_loss= 10.84342 reg_loss= 0.05813
05/21/2022 21:56:10 - INFO: Mini batch Iter: 19 train_loss= 10.91265 graph_loss= 10.85435 reg_loss= 0.05830
05/21/2022 21:56:13 - INFO: Mini batch Iter: 20 train_loss= 10.79644 graph_loss= 10.73792 reg_loss= 0.05852
05/21/2022 21:56:15 - INFO: Mini batch Iter: 21 train_loss= 10.83130 graph_loss= 10.77252 reg_loss= 0.05878
05/21/2022 21:56:18 - INFO: Mini batch Iter: 22 train_loss= 10.90333 graph_loss= 10.84426 reg_loss= 0.05907
05/21/2022 21:56:20 - INFO: Mini batch Iter: 23 train_loss= 10.91208 graph_loss= 10.85268 reg_loss= 0.05940
05/21/2022 21:56:23 - INFO: Mini batch Iter: 24 train_loss= 10.73324 graph_loss= 10.67352 reg_loss= 0.05972
05/21/2022 21:56:25 - INFO: Mini batch Iter: 25 train_loss= 10.81395 graph_loss= 10.75384 reg_loss= 0.06011
05/21/2022 21:56:28 - INFO: Mini batch Iter: 26 train_loss= 10.80888 graph_loss= 10.74836 reg_loss= 0.06052
05/21/2022 21:56:30 - INFO: Mini batch Iter: 27 train_loss= 10.69705 graph_loss= 10.63611 reg_loss= 0.06094
05/21/2022 21:56:32 - INFO: Mini batch Iter: 28 train_loss= 10.76444 graph_loss= 10.70304 reg_loss= 0.06140
05/21/2022 21:56:35 - INFO: Mini batch Iter: 29 train_loss= 10.83685 graph_loss= 10.77493 reg_loss= 0.06192
05/21/2022 21:56:38 - INFO: Mini batch Iter: 30 train_loss= 10.77149 graph_loss= 10.70904 reg_loss= 0.06245
05/21/2022 21:56:40 - INFO: Mini batch Iter: 31 train_loss= 10.86994 graph_loss= 10.80697 reg_loss= 0.06297
05/21/2022 21:56:43 - INFO: Mini batch Iter: 32 train_loss= 10.77440 graph_loss= 10.71096 reg_loss= 0.06344
05/21/2022 21:56:46 - INFO: Mini batch Iter: 33 train_loss= 10.97709 graph_loss= 10.91316 reg_loss= 0.06393
05/21/2022 21:56:48 - INFO: Mini batch Iter: 34 train_loss= 10.85508 graph_loss= 10.79077 reg_loss= 0.06432
05/21/2022 21:56:51 - INFO: Mini batch Iter: 35 train_loss= 10.70440 graph_loss= 10.63971 reg_loss= 0.06469
05/21/2022 21:56:53 - INFO: Mini batch Iter: 36 train_loss= 10.72702 graph_loss= 10.66195 reg_loss= 0.06507
05/21/2022 21:56:56 - INFO: Mini batch Iter: 37 train_loss= 10.71704 graph_loss= 10.65156 reg_loss= 0.06547
05/21/2022 21:56:58 - INFO: Mini batch Iter: 38 train_loss= 10.67583 graph_loss= 10.60994 reg_loss= 0.06589
05/21/2022 21:57:00 - INFO: Mini batch Iter: 39 train_loss= 11.00137 graph_loss= 10.93502 reg_loss= 0.06635
05/21/2022 21:57:00 - INFO: Time for epoch : 89.94083952903748
05/21/2022 22:01:58 - INFO: Test results at epoch 0: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228E17AC2F0>, {'operator_hadamard': [0.9471711680409987, 0.9471711680409987]}) best is : operator_hadamard 0.9471711680409987
05/21/2022 22:02:00 - INFO: Mini batch Iter: 0 train_loss= 10.64521 graph_loss= 10.57844 reg_loss= 0.06677
05/21/2022 22:02:03 - INFO: Mini batch Iter: 1 train_loss= 10.73447 graph_loss= 10.66723 reg_loss= 0.06724
05/21/2022 22:02:06 - INFO: Mini batch Iter: 2 train_loss= 10.79446 graph_loss= 10.72669 reg_loss= 0.06777
05/21/2022 22:02:08 - INFO: Mini batch Iter: 3 train_loss= 10.68545 graph_loss= 10.61721 reg_loss= 0.06824
05/21/2022 22:02:10 - INFO: Mini batch Iter: 4 train_loss= 10.62920 graph_loss= 10.56042 reg_loss= 0.06878
05/21/2022 22:02:13 - INFO: Mini batch Iter: 5 train_loss= 10.65026 graph_loss= 10.58088 reg_loss= 0.06938
05/21/2022 22:02:15 - INFO: Mini batch Iter: 6 train_loss= 10.68924 graph_loss= 10.61926 reg_loss= 0.06999
05/21/2022 22:02:18 - INFO: Mini batch Iter: 7 train_loss= 10.78305 graph_loss= 10.71251 reg_loss= 0.07053
05/21/2022 22:02:22 - INFO: Mini batch Iter: 8 train_loss= 10.71683 graph_loss= 10.64577 reg_loss= 0.07106
05/21/2022 22:02:24 - INFO: Mini batch Iter: 9 train_loss= 10.51246 graph_loss= 10.44085 reg_loss= 0.07161
05/21/2022 22:02:27 - INFO: Mini batch Iter: 10 train_loss= 10.97302 graph_loss= 10.90082 reg_loss= 0.07220
05/21/2022 22:02:29 - INFO: Mini batch Iter: 11 train_loss= 10.64682 graph_loss= 10.57418 reg_loss= 0.07265
05/21/2022 22:02:32 - INFO: Mini batch Iter: 12 train_loss= 10.85009 graph_loss= 10.77702 reg_loss= 0.07307
05/21/2022 22:02:35 - INFO: Mini batch Iter: 13 train_loss= 10.60072 graph_loss= 10.52731 reg_loss= 0.07341
05/21/2022 22:02:37 - INFO: Mini batch Iter: 14 train_loss= 10.64786 graph_loss= 10.57406 reg_loss= 0.07380
05/21/2022 22:02:40 - INFO: Mini batch Iter: 15 train_loss= 10.69521 graph_loss= 10.62098 reg_loss= 0.07423
05/21/2022 22:02:43 - INFO: Mini batch Iter: 16 train_loss= 10.66862 graph_loss= 10.59396 reg_loss= 0.07467
05/21/2022 22:02:45 - INFO: Mini batch Iter: 17 train_loss= 10.72052 graph_loss= 10.64546 reg_loss= 0.07505
05/21/2022 22:02:49 - INFO: Mini batch Iter: 18 train_loss= 13.16039 graph_loss= 13.08493 reg_loss= 0.07546
05/21/2022 22:02:51 - INFO: Mini batch Iter: 19 train_loss= 10.63031 graph_loss= 10.55476 reg_loss= 0.07555
05/21/2022 22:02:54 - INFO: Mini batch Iter: 20 train_loss= 10.64879 graph_loss= 10.57309 reg_loss= 0.07570
05/21/2022 22:02:56 - INFO: Mini batch Iter: 21 train_loss= 10.61032 graph_loss= 10.53442 reg_loss= 0.07590
05/21/2022 22:02:59 - INFO: Mini batch Iter: 22 train_loss= 10.67044 graph_loss= 10.59426 reg_loss= 0.07618
05/21/2022 22:03:01 - INFO: Mini batch Iter: 23 train_loss= 10.67010 graph_loss= 10.59355 reg_loss= 0.07655
05/21/2022 22:03:04 - INFO: Mini batch Iter: 24 train_loss= 10.61741 graph_loss= 10.54055 reg_loss= 0.07687
05/21/2022 22:03:07 - INFO: Mini batch Iter: 25 train_loss= 10.53044 graph_loss= 10.45321 reg_loss= 0.07722
05/21/2022 22:03:09 - INFO: Mini batch Iter: 26 train_loss= 10.53954 graph_loss= 10.46190 reg_loss= 0.07764
05/21/2022 22:03:12 - INFO: Mini batch Iter: 27 train_loss= 10.67996 graph_loss= 10.60184 reg_loss= 0.07811
05/21/2022 22:03:15 - INFO: Mini batch Iter: 28 train_loss= 10.82876 graph_loss= 10.75016 reg_loss= 0.07860
05/21/2022 22:03:17 - INFO: Mini batch Iter: 29 train_loss= 10.69208 graph_loss= 10.61308 reg_loss= 0.07900
05/21/2022 22:03:20 - INFO: Mini batch Iter: 30 train_loss= 10.77991 graph_loss= 10.70051 reg_loss= 0.07940
05/21/2022 22:03:22 - INFO: Mini batch Iter: 31 train_loss= 10.68826 graph_loss= 10.60848 reg_loss= 0.07978
05/21/2022 22:03:26 - INFO: Mini batch Iter: 32 train_loss= 11.26698 graph_loss= 11.18678 reg_loss= 0.08020
05/21/2022 22:03:28 - INFO: Mini batch Iter: 33 train_loss= 10.57973 graph_loss= 10.49936 reg_loss= 0.08036
05/21/2022 22:03:31 - INFO: Mini batch Iter: 34 train_loss= 10.53386 graph_loss= 10.45322 reg_loss= 0.08064
05/21/2022 22:03:33 - INFO: Mini batch Iter: 35 train_loss= 10.95810 graph_loss= 10.87712 reg_loss= 0.08098
05/21/2022 22:03:36 - INFO: Mini batch Iter: 36 train_loss= 10.70252 graph_loss= 10.62127 reg_loss= 0.08124
05/21/2022 22:03:39 - INFO: Mini batch Iter: 37 train_loss= 10.79780 graph_loss= 10.71626 reg_loss= 0.08154
05/21/2022 22:03:41 - INFO: Mini batch Iter: 38 train_loss= 10.67951 graph_loss= 10.59771 reg_loss= 0.08180
05/21/2022 22:03:43 - INFO: Mini batch Iter: 39 train_loss= 10.93464 graph_loss= 10.85255 reg_loss= 0.08209
05/21/2022 22:03:43 - INFO: Time for epoch : 71.35614562034607
05/21/2022 22:09:06 - INFO: Test results at epoch 1: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228E17B7D90>, {'operator_hadamard': [0.9435345943681543, 0.9435345943681543]}) best is : operator_hadamard 0.9435345943681543
05/21/2022 22:09:09 - INFO: Mini batch Iter: 0 train_loss= 11.69856 graph_loss= 11.61617 reg_loss= 0.08239
05/21/2022 22:09:12 - INFO: Mini batch Iter: 1 train_loss= 10.69894 graph_loss= 10.61641 reg_loss= 0.08253
05/21/2022 22:09:15 - INFO: Mini batch Iter: 2 train_loss= 10.71356 graph_loss= 10.63086 reg_loss= 0.08269
05/21/2022 22:09:17 - INFO: Mini batch Iter: 3 train_loss= 10.69394 graph_loss= 10.61106 reg_loss= 0.08288
05/21/2022 22:09:20 - INFO: Mini batch Iter: 4 train_loss= 10.78765 graph_loss= 10.70457 reg_loss= 0.08309
05/21/2022 22:09:23 - INFO: Mini batch Iter: 5 train_loss= 10.66927 graph_loss= 10.58599 reg_loss= 0.08328
05/21/2022 22:09:25 - INFO: Mini batch Iter: 6 train_loss= 10.68370 graph_loss= 10.60022 reg_loss= 0.08348
05/21/2022 22:09:28 - INFO: Mini batch Iter: 7 train_loss= 10.63917 graph_loss= 10.55549 reg_loss= 0.08368
05/21/2022 22:09:31 - INFO: Mini batch Iter: 8 train_loss= 10.51955 graph_loss= 10.43562 reg_loss= 0.08393
05/21/2022 22:09:33 - INFO: Mini batch Iter: 9 train_loss= 10.78552 graph_loss= 10.70128 reg_loss= 0.08424
05/21/2022 22:09:36 - INFO: Mini batch Iter: 10 train_loss= 13.91245 graph_loss= 13.82794 reg_loss= 0.08451
05/21/2022 22:09:39 - INFO: Mini batch Iter: 11 train_loss= 10.64765 graph_loss= 10.56298 reg_loss= 0.08467
05/21/2022 22:09:42 - INFO: Mini batch Iter: 12 train_loss= 10.58487 graph_loss= 10.50000 reg_loss= 0.08487
05/21/2022 22:09:45 - INFO: Mini batch Iter: 13 train_loss= 10.60661 graph_loss= 10.52149 reg_loss= 0.08512
05/21/2022 22:09:47 - INFO: Mini batch Iter: 14 train_loss= 10.63533 graph_loss= 10.54992 reg_loss= 0.08541
05/21/2022 22:09:49 - INFO: Mini batch Iter: 15 train_loss= 10.59984 graph_loss= 10.51414 reg_loss= 0.08570
05/21/2022 22:09:52 - INFO: Mini batch Iter: 16 train_loss= 10.58460 graph_loss= 10.49857 reg_loss= 0.08603
05/21/2022 22:09:54 - INFO: Mini batch Iter: 17 train_loss= 10.62208 graph_loss= 10.53568 reg_loss= 0.08640
05/21/2022 22:09:57 - INFO: Mini batch Iter: 18 train_loss= 10.58505 graph_loss= 10.49827 reg_loss= 0.08679
05/21/2022 22:10:00 - INFO: Mini batch Iter: 19 train_loss= 10.57641 graph_loss= 10.48921 reg_loss= 0.08720
05/21/2022 22:10:02 - INFO: Mini batch Iter: 20 train_loss= 10.74799 graph_loss= 10.66036 reg_loss= 0.08763
05/21/2022 22:10:06 - INFO: Mini batch Iter: 21 train_loss= 10.71047 graph_loss= 10.62246 reg_loss= 0.08801
05/21/2022 22:10:08 - INFO: Mini batch Iter: 22 train_loss= 10.54083 graph_loss= 10.45250 reg_loss= 0.08834
05/21/2022 22:10:11 - INFO: Mini batch Iter: 23 train_loss= 10.78317 graph_loss= 10.69444 reg_loss= 0.08873
05/21/2022 22:10:13 - INFO: Mini batch Iter: 24 train_loss= 10.49259 graph_loss= 10.40351 reg_loss= 0.08907
05/21/2022 22:10:16 - INFO: Mini batch Iter: 25 train_loss= 10.69169 graph_loss= 10.60222 reg_loss= 0.08946
05/21/2022 22:10:18 - INFO: Mini batch Iter: 26 train_loss= 10.69903 graph_loss= 10.60918 reg_loss= 0.08986
05/21/2022 22:10:21 - INFO: Mini batch Iter: 27 train_loss= 10.66825 graph_loss= 10.57800 reg_loss= 0.09025
05/21/2022 22:10:23 - INFO: Mini batch Iter: 28 train_loss= 10.62205 graph_loss= 10.53141 reg_loss= 0.09064
05/21/2022 22:10:26 - INFO: Mini batch Iter: 29 train_loss= 10.66271 graph_loss= 10.57170 reg_loss= 0.09101
05/21/2022 22:10:29 - INFO: Mini batch Iter: 30 train_loss= 10.62071 graph_loss= 10.52931 reg_loss= 0.09140
05/21/2022 22:10:32 - INFO: Mini batch Iter: 31 train_loss= 10.65818 graph_loss= 10.56640 reg_loss= 0.09178
05/21/2022 22:10:34 - INFO: Mini batch Iter: 32 train_loss= 10.60587 graph_loss= 10.51372 reg_loss= 0.09215
05/21/2022 22:10:37 - INFO: Mini batch Iter: 33 train_loss= 10.63946 graph_loss= 10.54689 reg_loss= 0.09257
05/21/2022 22:10:39 - INFO: Mini batch Iter: 34 train_loss= 10.61809 graph_loss= 10.52511 reg_loss= 0.09298
05/21/2022 22:10:41 - INFO: Mini batch Iter: 35 train_loss= 10.54214 graph_loss= 10.44873 reg_loss= 0.09341
05/21/2022 22:10:44 - INFO: Mini batch Iter: 36 train_loss= 10.71715 graph_loss= 10.62328 reg_loss= 0.09388
05/21/2022 22:10:46 - INFO: Mini batch Iter: 37 train_loss= 10.72212 graph_loss= 10.62782 reg_loss= 0.09430
05/21/2022 22:10:49 - INFO: Mini batch Iter: 38 train_loss= 10.48959 graph_loss= 10.39491 reg_loss= 0.09468
05/21/2022 22:10:50 - INFO: Mini batch Iter: 39 train_loss= 10.63579 graph_loss= 10.54068 reg_loss= 0.09511
05/21/2022 22:10:50 - INFO: Time for epoch : 69.91462969779968
05/21/2022 22:19:28 - INFO: Test results at epoch 2: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228E17AF2F0>, {'operator_hadamard': [0.9515579190245441, 0.9515579190245441]}) best is : operator_hadamard 0.9515579190245441
05/21/2022 22:19:30 - INFO: Mini batch Iter: 0 train_loss= 10.50231 graph_loss= 10.40684 reg_loss= 0.09547
05/21/2022 22:19:33 - INFO: Mini batch Iter: 1 train_loss= 10.54442 graph_loss= 10.44854 reg_loss= 0.09588
05/21/2022 22:19:35 - INFO: Mini batch Iter: 2 train_loss= 10.55199 graph_loss= 10.45566 reg_loss= 0.09632
05/21/2022 22:19:38 - INFO: Mini batch Iter: 3 train_loss= 10.42615 graph_loss= 10.32937 reg_loss= 0.09678
05/21/2022 22:19:40 - INFO: Mini batch Iter: 4 train_loss= 10.60510 graph_loss= 10.50783 reg_loss= 0.09726
05/21/2022 22:19:43 - INFO: Mini batch Iter: 5 train_loss= 10.85119 graph_loss= 10.75344 reg_loss= 0.09775
05/21/2022 22:19:46 - INFO: Mini batch Iter: 6 train_loss= 10.68470 graph_loss= 10.58656 reg_loss= 0.09814
05/21/2022 22:19:49 - INFO: Mini batch Iter: 7 train_loss= 10.65989 graph_loss= 10.56137 reg_loss= 0.09853
05/21/2022 22:19:51 - INFO: Mini batch Iter: 8 train_loss= 10.65079 graph_loss= 10.55194 reg_loss= 0.09885
05/21/2022 22:19:54 - INFO: Mini batch Iter: 9 train_loss= 10.48614 graph_loss= 10.38699 reg_loss= 0.09915
05/21/2022 22:19:56 - INFO: Mini batch Iter: 10 train_loss= 10.39755 graph_loss= 10.29802 reg_loss= 0.09952
05/21/2022 22:19:59 - INFO: Mini batch Iter: 11 train_loss= 10.51873 graph_loss= 10.41879 reg_loss= 0.09994
05/21/2022 22:20:01 - INFO: Mini batch Iter: 12 train_loss= 10.49155 graph_loss= 10.39116 reg_loss= 0.10038
05/21/2022 22:20:04 - INFO: Mini batch Iter: 13 train_loss= 10.54941 graph_loss= 10.44855 reg_loss= 0.10086
05/21/2022 22:20:06 - INFO: Mini batch Iter: 14 train_loss= 10.60095 graph_loss= 10.49962 reg_loss= 0.10133
05/21/2022 22:20:09 - INFO: Mini batch Iter: 15 train_loss= 10.45667 graph_loss= 10.35487 reg_loss= 0.10180
05/21/2022 22:20:12 - INFO: Mini batch Iter: 16 train_loss= 11.24494 graph_loss= 11.14265 reg_loss= 0.10228
05/21/2022 22:20:15 - INFO: Mini batch Iter: 17 train_loss= 10.52525 graph_loss= 10.42270 reg_loss= 0.10255
05/21/2022 22:20:17 - INFO: Mini batch Iter: 18 train_loss= 10.54214 graph_loss= 10.43931 reg_loss= 0.10283
05/21/2022 22:20:20 - INFO: Mini batch Iter: 19 train_loss= 10.75457 graph_loss= 10.65142 reg_loss= 0.10315
05/21/2022 22:20:23 - INFO: Mini batch Iter: 20 train_loss= 10.62029 graph_loss= 10.51692 reg_loss= 0.10337
05/21/2022 22:20:25 - INFO: Mini batch Iter: 21 train_loss= 10.75080 graph_loss= 10.64723 reg_loss= 0.10357
05/21/2022 22:20:27 - INFO: Mini batch Iter: 22 train_loss= 10.48712 graph_loss= 10.38338 reg_loss= 0.10374
05/21/2022 22:20:30 - INFO: Mini batch Iter: 23 train_loss= 10.68315 graph_loss= 10.57921 reg_loss= 0.10394
05/21/2022 22:20:33 - INFO: Mini batch Iter: 24 train_loss= 10.57054 graph_loss= 10.46638 reg_loss= 0.10415
05/21/2022 22:20:35 - INFO: Mini batch Iter: 25 train_loss= 10.60625 graph_loss= 10.50189 reg_loss= 0.10436
05/21/2022 22:20:38 - INFO: Mini batch Iter: 26 train_loss= 10.57890 graph_loss= 10.47431 reg_loss= 0.10459
05/21/2022 22:20:41 - INFO: Mini batch Iter: 27 train_loss= 10.65540 graph_loss= 10.55057 reg_loss= 0.10483
05/21/2022 22:20:43 - INFO: Mini batch Iter: 28 train_loss= 10.64810 graph_loss= 10.54301 reg_loss= 0.10509
05/21/2022 22:20:46 - INFO: Mini batch Iter: 29 train_loss= 10.57923 graph_loss= 10.47389 reg_loss= 0.10534
05/21/2022 22:20:48 - INFO: Mini batch Iter: 30 train_loss= 10.85019 graph_loss= 10.74456 reg_loss= 0.10563
05/21/2022 22:20:51 - INFO: Mini batch Iter: 31 train_loss= 10.42721 graph_loss= 10.32140 reg_loss= 0.10581
05/21/2022 22:20:54 - INFO: Mini batch Iter: 32 train_loss= 10.70949 graph_loss= 10.60343 reg_loss= 0.10606
05/21/2022 22:20:57 - INFO: Mini batch Iter: 33 train_loss= 10.71569 graph_loss= 10.60941 reg_loss= 0.10627
05/21/2022 22:21:00 - INFO: Mini batch Iter: 34 train_loss= 10.53769 graph_loss= 10.43122 reg_loss= 0.10648
05/21/2022 22:21:03 - INFO: Mini batch Iter: 35 train_loss= 10.56887 graph_loss= 10.46213 reg_loss= 0.10674
05/21/2022 22:21:06 - INFO: Mini batch Iter: 36 train_loss= 10.55322 graph_loss= 10.44611 reg_loss= 0.10711
05/21/2022 22:21:09 - INFO: Mini batch Iter: 37 train_loss= 10.51168 graph_loss= 10.40418 reg_loss= 0.10750
05/21/2022 22:21:11 - INFO: Mini batch Iter: 38 train_loss= 10.54141 graph_loss= 10.43349 reg_loss= 0.10792
05/21/2022 22:21:13 - INFO: Mini batch Iter: 39 train_loss= 10.29931 graph_loss= 10.19095 reg_loss= 0.10836
05/21/2022 22:21:13 - INFO: Time for epoch : 70.84456586837769
05/21/2022 22:27:53 - INFO: Test results at epoch 3: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228E17AF0D0>, {'operator_hadamard': [0.9518582142528272, 0.9518582142528272]}) best is : operator_hadamard 0.9518582142528272
05/21/2022 22:27:56 - INFO: Mini batch Iter: 0 train_loss= 10.55925 graph_loss= 10.45043 reg_loss= 0.10882
05/21/2022 22:27:58 - INFO: Mini batch Iter: 1 train_loss= 10.52557 graph_loss= 10.41628 reg_loss= 0.10928
05/21/2022 22:28:01 - INFO: Mini batch Iter: 2 train_loss= 10.63319 graph_loss= 10.52347 reg_loss= 0.10972
05/21/2022 22:28:04 - INFO: Mini batch Iter: 3 train_loss= 10.38996 graph_loss= 10.27985 reg_loss= 0.11011
05/21/2022 22:28:06 - INFO: Mini batch Iter: 4 train_loss= 10.65960 graph_loss= 10.54910 reg_loss= 0.11050
05/21/2022 22:28:09 - INFO: Mini batch Iter: 5 train_loss= 10.52718 graph_loss= 10.41635 reg_loss= 0.11083
05/21/2022 22:28:12 - INFO: Mini batch Iter: 6 train_loss= 11.23572 graph_loss= 11.12451 reg_loss= 0.11121
05/21/2022 22:28:15 - INFO: Mini batch Iter: 7 train_loss= 10.41460 graph_loss= 10.30320 reg_loss= 0.11140
05/21/2022 22:28:18 - INFO: Mini batch Iter: 8 train_loss= 10.58047 graph_loss= 10.46885 reg_loss= 0.11161
05/21/2022 22:28:20 - INFO: Mini batch Iter: 9 train_loss= 10.67189 graph_loss= 10.56005 reg_loss= 0.11184
05/21/2022 22:28:23 - INFO: Mini batch Iter: 10 train_loss= 10.65085 graph_loss= 10.53885 reg_loss= 0.11200
05/21/2022 22:28:25 - INFO: Mini batch Iter: 11 train_loss= 10.51051 graph_loss= 10.39836 reg_loss= 0.11215
05/21/2022 22:28:28 - INFO: Mini batch Iter: 12 train_loss= 10.61057 graph_loss= 10.49822 reg_loss= 0.11236
05/21/2022 22:28:30 - INFO: Mini batch Iter: 13 train_loss= 10.71360 graph_loss= 10.60104 reg_loss= 0.11256
05/21/2022 22:28:33 - INFO: Mini batch Iter: 14 train_loss= 10.53481 graph_loss= 10.42212 reg_loss= 0.11270
05/21/2022 22:28:35 - INFO: Mini batch Iter: 15 train_loss= 10.44543 graph_loss= 10.33258 reg_loss= 0.11285
05/21/2022 22:28:38 - INFO: Mini batch Iter: 16 train_loss= 10.59995 graph_loss= 10.48687 reg_loss= 0.11308
05/21/2022 22:28:41 - INFO: Mini batch Iter: 17 train_loss= 10.52315 graph_loss= 10.40987 reg_loss= 0.11328
05/21/2022 22:28:44 - INFO: Mini batch Iter: 18 train_loss= 10.94786 graph_loss= 10.83435 reg_loss= 0.11351
05/21/2022 22:28:46 - INFO: Mini batch Iter: 19 train_loss= 10.43339 graph_loss= 10.31980 reg_loss= 0.11359
05/21/2022 22:28:49 - INFO: Mini batch Iter: 20 train_loss= 10.41226 graph_loss= 10.29852 reg_loss= 0.11375
05/21/2022 22:28:52 - INFO: Mini batch Iter: 21 train_loss= 10.51252 graph_loss= 10.39853 reg_loss= 0.11398
05/21/2022 22:28:54 - INFO: Mini batch Iter: 22 train_loss= 10.45914 graph_loss= 10.34488 reg_loss= 0.11426
05/21/2022 22:28:57 - INFO: Mini batch Iter: 23 train_loss= 10.45376 graph_loss= 10.33915 reg_loss= 0.11461
05/21/2022 22:29:00 - INFO: Mini batch Iter: 24 train_loss= 10.56950 graph_loss= 10.45451 reg_loss= 0.11499
05/21/2022 22:29:03 - INFO: Mini batch Iter: 25 train_loss= 10.66252 graph_loss= 10.54714 reg_loss= 0.11538
05/21/2022 22:29:06 - INFO: Mini batch Iter: 26 train_loss= 10.54796 graph_loss= 10.43218 reg_loss= 0.11578
05/21/2022 22:29:08 - INFO: Mini batch Iter: 27 train_loss= 10.67706 graph_loss= 10.56087 reg_loss= 0.11618
05/21/2022 22:29:10 - INFO: Mini batch Iter: 28 train_loss= 10.58757 graph_loss= 10.47100 reg_loss= 0.11657
05/21/2022 22:29:14 - INFO: Mini batch Iter: 29 train_loss= 10.84266 graph_loss= 10.72571 reg_loss= 0.11696
05/21/2022 22:29:17 - INFO: Mini batch Iter: 30 train_loss= 10.37668 graph_loss= 10.25947 reg_loss= 0.11721
05/21/2022 22:29:19 - INFO: Mini batch Iter: 31 train_loss= 10.42003 graph_loss= 10.30249 reg_loss= 0.11754
05/21/2022 22:29:22 - INFO: Mini batch Iter: 32 train_loss= 10.53880 graph_loss= 10.42085 reg_loss= 0.11794
05/21/2022 22:29:24 - INFO: Mini batch Iter: 33 train_loss= 10.56249 graph_loss= 10.44413 reg_loss= 0.11836
05/21/2022 22:29:27 - INFO: Mini batch Iter: 34 train_loss= 10.72899 graph_loss= 10.61018 reg_loss= 0.11882
05/21/2022 22:29:29 - INFO: Mini batch Iter: 35 train_loss= 10.54304 graph_loss= 10.42383 reg_loss= 0.11921
05/21/2022 22:29:32 - INFO: Mini batch Iter: 36 train_loss= 10.73410 graph_loss= 10.61449 reg_loss= 0.11961
05/21/2022 22:29:34 - INFO: Mini batch Iter: 37 train_loss= 10.49484 graph_loss= 10.37490 reg_loss= 0.11995
05/21/2022 22:29:37 - INFO: Mini batch Iter: 38 train_loss= 10.47759 graph_loss= 10.35728 reg_loss= 0.12031
05/21/2022 22:29:38 - INFO: Mini batch Iter: 39 train_loss= 10.55909 graph_loss= 10.43841 reg_loss= 0.12068
05/21/2022 22:29:38 - INFO: Time for epoch : 70.78023648262024
05/21/2022 22:34:57 - INFO: Test results at epoch 4: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228E17AF2F0>, {'operator_hadamard': [0.9568561951304118, 0.9568561951304118]}) best is : operator_hadamard 0.9568561951304118
05/21/2022 22:35:00 - INFO: Mini batch Iter: 0 train_loss= 10.50471 graph_loss= 10.38370 reg_loss= 0.12102
05/21/2022 22:35:03 - INFO: Mini batch Iter: 1 train_loss= 10.61693 graph_loss= 10.49557 reg_loss= 0.12136
05/21/2022 22:35:05 - INFO: Mini batch Iter: 2 train_loss= 10.58208 graph_loss= 10.46041 reg_loss= 0.12166
05/21/2022 22:35:08 - INFO: Mini batch Iter: 3 train_loss= 10.55206 graph_loss= 10.43012 reg_loss= 0.12194
05/21/2022 22:35:11 - INFO: Mini batch Iter: 4 train_loss= 10.56831 graph_loss= 10.44608 reg_loss= 0.12223
05/21/2022 22:35:13 - INFO: Mini batch Iter: 5 train_loss= 10.60885 graph_loss= 10.48639 reg_loss= 0.12246
05/21/2022 22:35:17 - INFO: Mini batch Iter: 6 train_loss= 11.25145 graph_loss= 11.12881 reg_loss= 0.12264
05/21/2022 22:35:20 - INFO: Mini batch Iter: 7 train_loss= 10.54474 graph_loss= 10.42208 reg_loss= 0.12266
05/21/2022 22:35:22 - INFO: Mini batch Iter: 8 train_loss= 10.44189 graph_loss= 10.31925 reg_loss= 0.12264
05/21/2022 22:35:25 - INFO: Mini batch Iter: 9 train_loss= 10.64237 graph_loss= 10.51965 reg_loss= 0.12272
05/21/2022 22:35:28 - INFO: Mini batch Iter: 10 train_loss= 10.59756 graph_loss= 10.47480 reg_loss= 0.12276
05/21/2022 22:35:30 - INFO: Mini batch Iter: 11 train_loss= 10.41415 graph_loss= 10.29134 reg_loss= 0.12281
05/21/2022 22:35:32 - INFO: Mini batch Iter: 12 train_loss= 10.53303 graph_loss= 10.41009 reg_loss= 0.12294
05/21/2022 22:35:35 - INFO: Mini batch Iter: 13 train_loss= 10.60428 graph_loss= 10.48120 reg_loss= 0.12308
05/21/2022 22:35:38 - INFO: Mini batch Iter: 14 train_loss= 10.45092 graph_loss= 10.32769 reg_loss= 0.12323
05/21/2022 22:35:40 - INFO: Mini batch Iter: 15 train_loss= 10.52495 graph_loss= 10.40152 reg_loss= 0.12343
05/21/2022 22:35:43 - INFO: Mini batch Iter: 16 train_loss= 10.85093 graph_loss= 10.72728 reg_loss= 0.12365
05/21/2022 22:35:46 - INFO: Mini batch Iter: 17 train_loss= 10.75276 graph_loss= 10.62897 reg_loss= 0.12379
05/21/2022 22:35:49 - INFO: Mini batch Iter: 18 train_loss= 10.30563 graph_loss= 10.18175 reg_loss= 0.12388
05/21/2022 22:35:51 - INFO: Mini batch Iter: 19 train_loss= 10.52149 graph_loss= 10.39742 reg_loss= 0.12407
05/21/2022 22:35:54 - INFO: Mini batch Iter: 20 train_loss= 11.27483 graph_loss= 11.15054 reg_loss= 0.12429
05/21/2022 22:35:57 - INFO: Mini batch Iter: 21 train_loss= 10.47142 graph_loss= 10.34715 reg_loss= 0.12427
05/21/2022 22:36:00 - INFO: Mini batch Iter: 22 train_loss= 10.73111 graph_loss= 10.60675 reg_loss= 0.12436
05/21/2022 22:36:03 - INFO: Mini batch Iter: 23 train_loss= 10.48177 graph_loss= 10.35737 reg_loss= 0.12440
05/21/2022 22:36:05 - INFO: Mini batch Iter: 24 train_loss= 10.57654 graph_loss= 10.45205 reg_loss= 0.12450
05/21/2022 22:36:08 - INFO: Mini batch Iter: 25 train_loss= 10.66123 graph_loss= 10.53663 reg_loss= 0.12460
05/21/2022 22:36:10 - INFO: Mini batch Iter: 26 train_loss= 10.55537 graph_loss= 10.43068 reg_loss= 0.12469
05/21/2022 22:36:13 - INFO: Mini batch Iter: 27 train_loss= 10.78903 graph_loss= 10.66418 reg_loss= 0.12485
05/21/2022 22:36:15 - INFO: Mini batch Iter: 28 train_loss= 10.56578 graph_loss= 10.44083 reg_loss= 0.12495
05/21/2022 22:36:18 - INFO: Mini batch Iter: 29 train_loss= 10.51971 graph_loss= 10.39461 reg_loss= 0.12510
05/21/2022 22:36:21 - INFO: Mini batch Iter: 30 train_loss= 10.59152 graph_loss= 10.46624 reg_loss= 0.12528
05/21/2022 22:36:23 - INFO: Mini batch Iter: 31 train_loss= 10.48713 graph_loss= 10.36166 reg_loss= 0.12547
05/21/2022 22:36:26 - INFO: Mini batch Iter: 32 train_loss= 10.59526 graph_loss= 10.46957 reg_loss= 0.12569
05/21/2022 22:36:28 - INFO: Mini batch Iter: 33 train_loss= 10.70549 graph_loss= 10.57957 reg_loss= 0.12593
05/21/2022 22:36:31 - INFO: Mini batch Iter: 34 train_loss= 10.57238 graph_loss= 10.44625 reg_loss= 0.12613
05/21/2022 22:36:33 - INFO: Mini batch Iter: 35 train_loss= 10.50767 graph_loss= 10.38132 reg_loss= 0.12635
05/21/2022 22:36:35 - INFO: Mini batch Iter: 36 train_loss= 10.55901 graph_loss= 10.43241 reg_loss= 0.12660
05/21/2022 22:36:38 - INFO: Mini batch Iter: 37 train_loss= 10.58887 graph_loss= 10.46200 reg_loss= 0.12687
05/21/2022 22:36:40 - INFO: Mini batch Iter: 38 train_loss= 10.50578 graph_loss= 10.37861 reg_loss= 0.12717
05/21/2022 22:36:42 - INFO: Mini batch Iter: 39 train_loss= 10.94212 graph_loss= 10.81463 reg_loss= 0.12750
05/21/2022 22:36:42 - INFO: Time for epoch : 70.54988932609558
05/21/2022 22:43:56 - INFO: Test results at epoch 5: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228C191DEA0>, {'operator_hadamard': [0.9527189578823116, 0.9527189578823116]}) best is : operator_hadamard 0.9527189578823116
05/21/2022 22:43:59 - INFO: Mini batch Iter: 0 train_loss= 10.59501 graph_loss= 10.46723 reg_loss= 0.12777
05/21/2022 22:44:01 - INFO: Mini batch Iter: 1 train_loss= 10.49286 graph_loss= 10.36483 reg_loss= 0.12803
05/21/2022 22:44:04 - INFO: Mini batch Iter: 2 train_loss= 10.69883 graph_loss= 10.57052 reg_loss= 0.12831
05/21/2022 22:44:07 - INFO: Mini batch Iter: 3 train_loss= 10.58881 graph_loss= 10.46031 reg_loss= 0.12850
05/21/2022 22:44:10 - INFO: Mini batch Iter: 4 train_loss= 10.64749 graph_loss= 10.51881 reg_loss= 0.12868
05/21/2022 22:44:12 - INFO: Mini batch Iter: 5 train_loss= 10.55730 graph_loss= 10.42847 reg_loss= 0.12883
05/21/2022 22:44:15 - INFO: Mini batch Iter: 6 train_loss= 10.45346 graph_loss= 10.32445 reg_loss= 0.12901
05/21/2022 22:44:17 - INFO: Mini batch Iter: 7 train_loss= 10.49447 graph_loss= 10.36522 reg_loss= 0.12925
05/21/2022 22:44:20 - INFO: Mini batch Iter: 8 train_loss= 10.60193 graph_loss= 10.47245 reg_loss= 0.12948
05/21/2022 22:44:23 - INFO: Mini batch Iter: 9 train_loss= 11.11762 graph_loss= 10.98794 reg_loss= 0.12969
05/21/2022 22:44:26 - INFO: Mini batch Iter: 10 train_loss= 10.46740 graph_loss= 10.33764 reg_loss= 0.12976
05/21/2022 22:44:28 - INFO: Mini batch Iter: 11 train_loss= 10.55916 graph_loss= 10.42927 reg_loss= 0.12989
05/21/2022 22:44:31 - INFO: Mini batch Iter: 12 train_loss= 10.78983 graph_loss= 10.65979 reg_loss= 0.13004
05/21/2022 22:44:34 - INFO: Mini batch Iter: 13 train_loss= 10.60871 graph_loss= 10.47854 reg_loss= 0.13016
05/21/2022 22:44:37 - INFO: Mini batch Iter: 14 train_loss= 10.57958 graph_loss= 10.44929 reg_loss= 0.13029
05/21/2022 22:44:39 - INFO: Mini batch Iter: 15 train_loss= 10.52527 graph_loss= 10.39482 reg_loss= 0.13045
05/21/2022 22:44:42 - INFO: Mini batch Iter: 16 train_loss= 10.50614 graph_loss= 10.37549 reg_loss= 0.13065
05/21/2022 22:44:44 - INFO: Mini batch Iter: 17 train_loss= 10.49626 graph_loss= 10.36537 reg_loss= 0.13089
05/21/2022 22:44:46 - INFO: Mini batch Iter: 18 train_loss= 10.56744 graph_loss= 10.43628 reg_loss= 0.13116
05/21/2022 22:44:49 - INFO: Mini batch Iter: 19 train_loss= 10.43624 graph_loss= 10.30482 reg_loss= 0.13141
05/21/2022 22:44:51 - INFO: Mini batch Iter: 20 train_loss= 10.57141 graph_loss= 10.43968 reg_loss= 0.13173
05/21/2022 22:44:54 - INFO: Mini batch Iter: 21 train_loss= 10.59700 graph_loss= 10.46495 reg_loss= 0.13205
05/21/2022 22:44:56 - INFO: Mini batch Iter: 22 train_loss= 10.53080 graph_loss= 10.39846 reg_loss= 0.13234
05/21/2022 22:44:59 - INFO: Mini batch Iter: 23 train_loss= 10.50311 graph_loss= 10.37049 reg_loss= 0.13262
05/21/2022 22:45:02 - INFO: Mini batch Iter: 24 train_loss= 12.05651 graph_loss= 11.92360 reg_loss= 0.13291
05/21/2022 22:45:05 - INFO: Mini batch Iter: 25 train_loss= 10.46390 graph_loss= 10.33073 reg_loss= 0.13316
05/21/2022 22:45:08 - INFO: Mini batch Iter: 26 train_loss= 10.51493 graph_loss= 10.38151 reg_loss= 0.13342
05/21/2022 22:45:10 - INFO: Mini batch Iter: 27 train_loss= 10.53641 graph_loss= 10.40276 reg_loss= 0.13365
05/21/2022 22:45:13 - INFO: Mini batch Iter: 28 train_loss= 10.78040 graph_loss= 10.64653 reg_loss= 0.13387
05/21/2022 22:45:15 - INFO: Mini batch Iter: 29 train_loss= 10.77067 graph_loss= 10.63667 reg_loss= 0.13400
05/21/2022 22:45:18 - INFO: Mini batch Iter: 30 train_loss= 10.33467 graph_loss= 10.20059 reg_loss= 0.13407
05/21/2022 22:45:21 - INFO: Mini batch Iter: 31 train_loss= 10.57546 graph_loss= 10.44124 reg_loss= 0.13422
05/21/2022 22:45:23 - INFO: Mini batch Iter: 32 train_loss= 10.67520 graph_loss= 10.54081 reg_loss= 0.13439
05/21/2022 22:45:25 - INFO: Mini batch Iter: 33 train_loss= 10.49916 graph_loss= 10.36464 reg_loss= 0.13452
05/21/2022 22:45:28 - INFO: Mini batch Iter: 34 train_loss= 10.44756 graph_loss= 10.31289 reg_loss= 0.13468
05/21/2022 22:45:30 - INFO: Mini batch Iter: 35 train_loss= 10.35259 graph_loss= 10.21770 reg_loss= 0.13489
05/21/2022 22:45:32 - INFO: Mini batch Iter: 36 train_loss= 10.52354 graph_loss= 10.38837 reg_loss= 0.13517
05/21/2022 22:45:35 - INFO: Mini batch Iter: 37 train_loss= 10.41009 graph_loss= 10.27463 reg_loss= 0.13546
05/21/2022 22:45:39 - INFO: Mini batch Iter: 38 train_loss= 11.09145 graph_loss= 10.95566 reg_loss= 0.13579
05/21/2022 22:45:40 - INFO: Mini batch Iter: 39 train_loss= 10.65093 graph_loss= 10.51500 reg_loss= 0.13593
05/21/2022 22:45:40 - INFO: Time for epoch : 70.21397638320923
05/21/2022 22:51:32 - INFO: Test results at epoch 6: AUC: defaultdict(<function evaluate_classifier.<locals>.<lambda> at 0x00000228E17AFE18>, {'operator_hadamard': [0.9574126274702042, 0.9574126274702042]}) best is : operator_hadamard 0.9574126274702042
05/21/2022 22:51:34 - INFO: Mini batch Iter: 0 train_loss= 10.48864 graph_loss= 10.35254 reg_loss= 0.13610
05/21/2022 22:51:37 - INFO: Mini batch Iter: 1 train_loss= 10.66008 graph_loss= 10.52376 reg_loss= 0.13632
05/21/2022 22:51:40 - INFO: Mini batch Iter: 2 train_loss= 10.68410 graph_loss= 10.54757 reg_loss= 0.13654
05/21/2022 22:51:42 - INFO: Mini batch Iter: 3 train_loss= 10.41929 graph_loss= 10.28257 reg_loss= 0.13672
05/21/2022 22:51:45 - INFO: Mini batch Iter: 4 train_loss= 10.45419 graph_loss= 10.31724 reg_loss= 0.13695
05/21/2022 22:51:47 - INFO: Mini batch Iter: 5 train_loss= 10.50298 graph_loss= 10.36574 reg_loss= 0.13724
05/21/2022 22:51:50 - INFO: Mini batch Iter: 6 train_loss= 10.48267 graph_loss= 10.34514 reg_loss= 0.13752
05/21/2022 22:51:52 - INFO: Mini batch Iter: 7 train_loss= 10.41135 graph_loss= 10.27355 reg_loss= 0.13781
05/21/2022 22:51:55 - INFO: Mini batch Iter: 8 train_loss= 10.41927 graph_loss= 10.28114 reg_loss= 0.13812
05/21/2022 22:51:57 - INFO: Mini batch Iter: 9 train_loss= 10.60773 graph_loss= 10.46929 reg_loss= 0.13844
05/21/2022 22:51:59 - INFO: Mini batch Iter: 10 train_loss= 10.40810 graph_loss= 10.26940 reg_loss= 0.13869
05/21/2022 22:52:02 - INFO: Mini batch Iter: 11 train_loss= 10.56181 graph_loss= 10.42283 reg_loss= 0.13897
05/21/2022 22:52:05 - INFO: Mini batch Iter: 12 train_loss= 11.07901 graph_loss= 10.93977 reg_loss= 0.13924
05/21/2022 22:52:07 - INFO: Mini batch Iter: 13 train_loss= 10.55436 graph_loss= 10.41508 reg_loss= 0.13928
05/21/2022 22:52:10 - INFO: Mini batch Iter: 14 train_loss= 10.51403 graph_loss= 10.37471 reg_loss= 0.13932
05/21/2022 22:52:13 - INFO: Mini batch Iter: 15 train_loss= 10.40485 graph_loss= 10.26553 reg_loss= 0.13933
05/21/2022 22:52:16 - INFO: Mini batch Iter: 16 train_loss= 10.64265 graph_loss= 10.50327 reg_loss= 0.13938
05/21/2022 22:52:19 - INFO: Mini batch Iter: 17 train_loss= 10.44612 graph_loss= 10.30669 reg_loss= 0.13943
05/21/2022 22:52:21 - INFO: Mini batch Iter: 18 train_loss= 10.53544 graph_loss= 10.39592 reg_loss= 0.13951
05/21/2022 22:52:24 - INFO: Mini batch Iter: 19 train_loss= 10.51484 graph_loss= 10.37519 reg_loss= 0.13965
05/21/2022 22:52:26 - INFO: Mini batch Iter: 20 train_loss= 10.44180 graph_loss= 10.30201 reg_loss= 0.13979
05/21/2022 22:52:28 - INFO: Mini batch Iter: 21 train_loss= 10.50467 graph_loss= 10.36467 reg_loss= 0.14000
05/21/2022 22:52:31 - INFO: Mini batch Iter: 22 train_loss= 10.45834 graph_loss= 10.31809 reg_loss= 0.14025
05/21/2022 22:52:34 - INFO: Mini batch Iter: 23 train_loss= 10.27858 graph_loss= 10.13807 reg_loss= 0.14051
05/21/2022 22:52:36 - INFO: Mini batch Iter: 24 train_loss= 10.46628 graph_loss= 10.32548 reg_loss= 0.14081
05/21/2022 22:52:38 - INFO: Mini batch Iter: 25 train_loss= 10.46949 graph_loss= 10.32839 reg_loss= 0.14109
05/21/2022 22:52:41 - INFO: Mini batch Iter: 26 train_loss= 10.43292 graph_loss= 10.29155 reg_loss= 0.14137
05/21/2022 22:52:44 - INFO: Mini batch Iter: 27 train_loss= 10.52132 graph_loss= 10.37966 reg_loss= 0.14166
05/21/2022 22:52:46 - INFO: Mini batch Iter: 28 train_loss= 10.41036 graph_loss= 10.26841 reg_loss= 0.14195
05/21/2022 22:52:49 - INFO: Mini batch Iter: 29 train_loss= 10.65734 graph_loss= 10.51509 reg_loss= 0.14226
05/21/2022 22:52:51 - INFO: Mini batch Iter: 30 train_loss= 10.71798 graph_loss= 10.57547 reg_loss= 0.14251
05/21/2022 22:52:54 - INFO: Mini batch Iter: 31 train_loss= 10.59140 graph_loss= 10.44868 reg_loss= 0.14272
05/21/2022 22:52:58 - INFO: Mini batch Iter: 32 train_loss= 10.46782 graph_loss= 10.32491 reg_loss= 0.14291
05/21/2022 22:53:00 - INFO: Mini batch Iter: 33 train_loss= 10.47996 graph_loss= 10.33683 reg_loss= 0.14313
05/21/2022 22:53:03 - INFO: Mini batch Iter: 34 train_loss= 10.58427 graph_loss= 10.44089 reg_loss= 0.14338
05/21/2022 22:53:06 - INFO: Mini batch Iter: 35 train_loss= 10.55837 graph_loss= 10.41477 reg_loss= 0.14360
05/21/2022 22:53:09 - INFO: Mini batch Iter: 36 train_loss= 10.83035 graph_loss= 10.68654 reg_loss= 0.14381
05/21/2022 22:53:12 - INFO: Mini batch Iter: 37 train_loss= 10.92616 graph_loss= 10.78223 reg_loss= 0.14393
05/21/2022 22:53:16 - INFO: Mini batch Iter: 38 train_loss= 11.85899 graph_loss= 11.71506 reg_loss= 0.14393
05/21/2022 22:53:17 - INFO: Mini batch Iter: 39 train_loss= 10.51150 graph_loss= 10.36758 reg_loss= 0.14392
05/21/2022 22:53:17 - INFO: Time for epoch : 70.90357708930969
